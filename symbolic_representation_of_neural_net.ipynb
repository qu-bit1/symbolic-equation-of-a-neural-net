{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOJwMQKaNDFqN4RCe5oMEUg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/qu-bit1/symbolic-equation-of-a-neural-net/blob/master/symbolic_representation_of_neural_net.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Task 3: Build Symbolic Equation from Neural Network Output**\n",
        "\n",
        "*Submitted by:*\n",
        "\n",
        "*Sagar Arora*(*220933*)\n",
        "\n",
        "This notebook consists of my majority of thought process (of course the relevant ones) while doing this task.\n",
        "\n",
        "### **How to run the notebook**:\n",
        "- Can run on CPU too.\n",
        "- Either press run all and go down the cell where you are prompted to enter an input of your choice.\n",
        "- Run each cell one by one till you reach the cell where you are prompted to enter an input of your choice."
      ],
      "metadata": {
        "id": "8eH_NRDdlnRH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Defining and training the neural network**"
      ],
      "metadata": {
        "id": "6qYvkU3q-n9e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing necessary libraries majorly numpy, tf, sklearn and sympy"
      ],
      "metadata": {
        "id": "5-oCtMkj9eql"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "import tensorflow as tf\n",
        "import sympy as sp"
      ],
      "metadata": {
        "id": "xnvxHqgU2de-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training on the Iris dataset.\n",
        "\n",
        "This data sets consists of 3 different types of irisesâ€™ (Setosa, Versicolour, and Virginica) petal and sepal length, stored in a 150x4 numpy.ndarray\n",
        "\n",
        "Therefore 4 possible input variables."
      ],
      "metadata": {
        "id": "-zUFoRpp9m4U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FuWYTdqTWzgD"
      },
      "outputs": [],
      "source": [
        "# Loading the iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I trained on a 2-hidden layer feedforward neural network with 6 neurons in both hidden layers with a total of 93 trainable parameters\n",
        "\n",
        "Following is the schematic of my neural network (drawn on excalidraw)"
      ],
      "metadata": {
        "id": "xEfpTAXj8hGG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Untitled-2024-02-03-2234 (1).png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "Xe6syJ868uI2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model architecture\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(4,)),\n",
        "    tf.keras.layers.Dense(6, activation='relu', kernel_initializer='random_normal'),\n",
        "    tf.keras.layers.Dense(6, activation='relu', kernel_initializer='random_normal'),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "d5jsSijQ2kcy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "dKHTM-MCZasa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VctuVTcH20Ud",
        "outputId": "6ccb124d-0a13-4727-c992-06e222fa8df3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 4)                 0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 6)                 30        \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 6)                 42        \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 3)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 93 (372.00 Byte)\n",
            "Trainable params: 93 (372.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X, y, epochs=200, batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQIYc_S12vRk",
        "outputId": "c4e1d720-cd62-4b3a-e3b2-6cd93e37b2ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "5/5 [==============================] - 1s 4ms/step - loss: 1.0980 - accuracy: 0.4333\n",
            "Epoch 2/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0969 - accuracy: 0.3600\n",
            "Epoch 3/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0965 - accuracy: 0.3533\n",
            "Epoch 4/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0964 - accuracy: 0.3333\n",
            "Epoch 5/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0960 - accuracy: 0.3333\n",
            "Epoch 6/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0958 - accuracy: 0.3467\n",
            "Epoch 7/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0956 - accuracy: 0.3600\n",
            "Epoch 8/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0952 - accuracy: 0.3600\n",
            "Epoch 9/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0949 - accuracy: 0.3467\n",
            "Epoch 10/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0946 - accuracy: 0.3533\n",
            "Epoch 11/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0941 - accuracy: 0.3333\n",
            "Epoch 12/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0939 - accuracy: 0.3333\n",
            "Epoch 13/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0932 - accuracy: 0.3333\n",
            "Epoch 14/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0925 - accuracy: 0.3333\n",
            "Epoch 15/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0919 - accuracy: 0.3333\n",
            "Epoch 16/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0910 - accuracy: 0.3333\n",
            "Epoch 17/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0902 - accuracy: 0.3333\n",
            "Epoch 18/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0892 - accuracy: 0.3333\n",
            "Epoch 19/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0881 - accuracy: 0.3333\n",
            "Epoch 20/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0866 - accuracy: 0.3333\n",
            "Epoch 21/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0852 - accuracy: 0.3333\n",
            "Epoch 22/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0836 - accuracy: 0.3333\n",
            "Epoch 23/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0817 - accuracy: 0.3333\n",
            "Epoch 24/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0800 - accuracy: 0.3333\n",
            "Epoch 25/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0779 - accuracy: 0.3333\n",
            "Epoch 26/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0756 - accuracy: 0.3333\n",
            "Epoch 27/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0731 - accuracy: 0.3333\n",
            "Epoch 28/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0708 - accuracy: 0.3333\n",
            "Epoch 29/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0682 - accuracy: 0.3333\n",
            "Epoch 30/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0656 - accuracy: 0.3333\n",
            "Epoch 31/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0627 - accuracy: 0.3333\n",
            "Epoch 32/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0595 - accuracy: 0.3333\n",
            "Epoch 33/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0563 - accuracy: 0.3333\n",
            "Epoch 34/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0533 - accuracy: 0.3333\n",
            "Epoch 35/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0498 - accuracy: 0.3333\n",
            "Epoch 36/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0468 - accuracy: 0.3333\n",
            "Epoch 37/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0429 - accuracy: 0.3333\n",
            "Epoch 38/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0392 - accuracy: 0.3333\n",
            "Epoch 39/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0356 - accuracy: 0.3333\n",
            "Epoch 40/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0317 - accuracy: 0.3333\n",
            "Epoch 41/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0281 - accuracy: 0.3333\n",
            "Epoch 42/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0239 - accuracy: 0.3333\n",
            "Epoch 43/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0210 - accuracy: 0.3333\n",
            "Epoch 44/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0162 - accuracy: 0.3333\n",
            "Epoch 45/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0122 - accuracy: 0.3333\n",
            "Epoch 46/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0084 - accuracy: 0.3333\n",
            "Epoch 47/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0042 - accuracy: 0.3333\n",
            "Epoch 48/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1.0005 - accuracy: 0.3333\n",
            "Epoch 49/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.9965 - accuracy: 0.3333\n",
            "Epoch 50/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.9923 - accuracy: 0.3333\n",
            "Epoch 51/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.9881 - accuracy: 0.3333\n",
            "Epoch 52/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.9839 - accuracy: 0.3333\n",
            "Epoch 53/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9798 - accuracy: 0.3333\n",
            "Epoch 54/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.9763 - accuracy: 0.3333\n",
            "Epoch 55/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.9718 - accuracy: 0.3333\n",
            "Epoch 56/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.9678 - accuracy: 0.3333\n",
            "Epoch 57/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.9636 - accuracy: 0.3333\n",
            "Epoch 58/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.9598 - accuracy: 0.3333\n",
            "Epoch 59/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.9558 - accuracy: 0.3333\n",
            "Epoch 60/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.9515 - accuracy: 0.3333\n",
            "Epoch 61/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.9472 - accuracy: 0.3333\n",
            "Epoch 62/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.9442 - accuracy: 0.3333\n",
            "Epoch 63/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.9400 - accuracy: 0.3333\n",
            "Epoch 64/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9359 - accuracy: 0.3333\n",
            "Epoch 65/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9320 - accuracy: 0.3333\n",
            "Epoch 66/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.9281 - accuracy: 0.3333\n",
            "Epoch 67/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9244 - accuracy: 0.3333\n",
            "Epoch 68/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9200 - accuracy: 0.3333\n",
            "Epoch 69/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9162 - accuracy: 0.3333\n",
            "Epoch 70/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9136 - accuracy: 0.3333\n",
            "Epoch 71/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9087 - accuracy: 0.5667\n",
            "Epoch 72/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9052 - accuracy: 0.6667\n",
            "Epoch 73/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9011 - accuracy: 0.6667\n",
            "Epoch 74/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8974 - accuracy: 0.6667\n",
            "Epoch 75/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.8937 - accuracy: 0.6667\n",
            "Epoch 76/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8901 - accuracy: 0.6667\n",
            "Epoch 77/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8861 - accuracy: 0.6667\n",
            "Epoch 78/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.8823 - accuracy: 0.6667\n",
            "Epoch 79/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.8786 - accuracy: 0.6667\n",
            "Epoch 80/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8751 - accuracy: 0.6667\n",
            "Epoch 81/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.8716 - accuracy: 0.6667\n",
            "Epoch 82/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.8680 - accuracy: 0.6667\n",
            "Epoch 83/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8640 - accuracy: 0.6667\n",
            "Epoch 84/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8604 - accuracy: 0.6667\n",
            "Epoch 85/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.8567 - accuracy: 0.6667\n",
            "Epoch 86/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.8531 - accuracy: 0.6667\n",
            "Epoch 87/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8500 - accuracy: 0.6667\n",
            "Epoch 88/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.8460 - accuracy: 0.6667\n",
            "Epoch 89/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.8425 - accuracy: 0.6667\n",
            "Epoch 90/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8390 - accuracy: 0.6667\n",
            "Epoch 91/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8355 - accuracy: 0.6667\n",
            "Epoch 92/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.8320 - accuracy: 0.6667\n",
            "Epoch 93/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8287 - accuracy: 0.6667\n",
            "Epoch 94/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.8248 - accuracy: 0.6667\n",
            "Epoch 95/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8214 - accuracy: 0.6667\n",
            "Epoch 96/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.8179 - accuracy: 0.6667\n",
            "Epoch 97/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.8146 - accuracy: 0.6667\n",
            "Epoch 98/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.8111 - accuracy: 0.6667\n",
            "Epoch 99/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.8078 - accuracy: 0.6667\n",
            "Epoch 100/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8043 - accuracy: 0.6733\n",
            "Epoch 101/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8011 - accuracy: 0.6733\n",
            "Epoch 102/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7978 - accuracy: 0.6733\n",
            "Epoch 103/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7944 - accuracy: 0.6733\n",
            "Epoch 104/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7910 - accuracy: 0.6733\n",
            "Epoch 105/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.7878 - accuracy: 0.6733\n",
            "Epoch 106/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7844 - accuracy: 0.6733\n",
            "Epoch 107/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.7812 - accuracy: 0.6733\n",
            "Epoch 108/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.7781 - accuracy: 0.6733\n",
            "Epoch 109/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7748 - accuracy: 0.6800\n",
            "Epoch 110/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.7715 - accuracy: 0.6800\n",
            "Epoch 111/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.7686 - accuracy: 0.6933\n",
            "Epoch 112/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7653 - accuracy: 0.6933\n",
            "Epoch 113/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.7621 - accuracy: 0.6867\n",
            "Epoch 114/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.7587 - accuracy: 0.6933\n",
            "Epoch 115/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.7557 - accuracy: 0.6933\n",
            "Epoch 116/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7528 - accuracy: 0.6933\n",
            "Epoch 117/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7497 - accuracy: 0.6933\n",
            "Epoch 118/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7465 - accuracy: 0.6933\n",
            "Epoch 119/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7434 - accuracy: 0.6933\n",
            "Epoch 120/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7407 - accuracy: 0.6933\n",
            "Epoch 121/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7380 - accuracy: 0.6933\n",
            "Epoch 122/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7345 - accuracy: 0.6933\n",
            "Epoch 123/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7316 - accuracy: 0.6933\n",
            "Epoch 124/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7288 - accuracy: 0.6933\n",
            "Epoch 125/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7261 - accuracy: 0.7000\n",
            "Epoch 126/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.7231 - accuracy: 0.7000\n",
            "Epoch 127/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7202 - accuracy: 0.7000\n",
            "Epoch 128/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7174 - accuracy: 0.7000\n",
            "Epoch 129/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7146 - accuracy: 0.7000\n",
            "Epoch 130/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7115 - accuracy: 0.7000\n",
            "Epoch 131/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7089 - accuracy: 0.7000\n",
            "Epoch 132/200\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.7066 - accuracy: 0.6933\n",
            "Epoch 133/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7035 - accuracy: 0.7000\n",
            "Epoch 134/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7007 - accuracy: 0.7000\n",
            "Epoch 135/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6980 - accuracy: 0.7067\n",
            "Epoch 136/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6954 - accuracy: 0.7067\n",
            "Epoch 137/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6928 - accuracy: 0.7067\n",
            "Epoch 138/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6901 - accuracy: 0.7067\n",
            "Epoch 139/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6876 - accuracy: 0.7067\n",
            "Epoch 140/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6851 - accuracy: 0.7067\n",
            "Epoch 141/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.6822 - accuracy: 0.7067\n",
            "Epoch 142/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6798 - accuracy: 0.7133\n",
            "Epoch 143/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6773 - accuracy: 0.7267\n",
            "Epoch 144/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6746 - accuracy: 0.7267\n",
            "Epoch 145/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6721 - accuracy: 0.7267\n",
            "Epoch 146/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6697 - accuracy: 0.7200\n",
            "Epoch 147/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6671 - accuracy: 0.7267\n",
            "Epoch 148/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6647 - accuracy: 0.7267\n",
            "Epoch 149/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6622 - accuracy: 0.7267\n",
            "Epoch 150/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6600 - accuracy: 0.7333\n",
            "Epoch 151/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6574 - accuracy: 0.7400\n",
            "Epoch 152/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6552 - accuracy: 0.7467\n",
            "Epoch 153/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6528 - accuracy: 0.7467\n",
            "Epoch 154/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6503 - accuracy: 0.7400\n",
            "Epoch 155/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6483 - accuracy: 0.7333\n",
            "Epoch 156/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6458 - accuracy: 0.7333\n",
            "Epoch 157/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6435 - accuracy: 0.7400\n",
            "Epoch 158/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6415 - accuracy: 0.7467\n",
            "Epoch 159/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6389 - accuracy: 0.7467\n",
            "Epoch 160/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6370 - accuracy: 0.7467\n",
            "Epoch 161/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6346 - accuracy: 0.7467\n",
            "Epoch 162/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6324 - accuracy: 0.7467\n",
            "Epoch 163/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6303 - accuracy: 0.7467\n",
            "Epoch 164/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6282 - accuracy: 0.7467\n",
            "Epoch 165/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6260 - accuracy: 0.7467\n",
            "Epoch 166/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6239 - accuracy: 0.7467\n",
            "Epoch 167/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6220 - accuracy: 0.7467\n",
            "Epoch 168/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6197 - accuracy: 0.7467\n",
            "Epoch 169/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6179 - accuracy: 0.7467\n",
            "Epoch 170/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6157 - accuracy: 0.7600\n",
            "Epoch 171/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.6139 - accuracy: 0.7600\n",
            "Epoch 172/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.6116 - accuracy: 0.7600\n",
            "Epoch 173/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6097 - accuracy: 0.7533\n",
            "Epoch 174/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6078 - accuracy: 0.7467\n",
            "Epoch 175/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6059 - accuracy: 0.7467\n",
            "Epoch 176/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6038 - accuracy: 0.7600\n",
            "Epoch 177/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.6020 - accuracy: 0.7600\n",
            "Epoch 178/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6001 - accuracy: 0.7600\n",
            "Epoch 179/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5983 - accuracy: 0.7667\n",
            "Epoch 180/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5964 - accuracy: 0.7667\n",
            "Epoch 181/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5945 - accuracy: 0.7667\n",
            "Epoch 182/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5928 - accuracy: 0.7667\n",
            "Epoch 183/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5910 - accuracy: 0.7667\n",
            "Epoch 184/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5892 - accuracy: 0.7667\n",
            "Epoch 185/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5873 - accuracy: 0.7667\n",
            "Epoch 186/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5856 - accuracy: 0.7667\n",
            "Epoch 187/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5837 - accuracy: 0.7667\n",
            "Epoch 188/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5821 - accuracy: 0.7667\n",
            "Epoch 189/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5803 - accuracy: 0.7667\n",
            "Epoch 190/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.5786 - accuracy: 0.7667\n",
            "Epoch 191/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5769 - accuracy: 0.7667\n",
            "Epoch 192/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5752 - accuracy: 0.7667\n",
            "Epoch 193/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5741 - accuracy: 0.7667\n",
            "Epoch 194/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5719 - accuracy: 0.7733\n",
            "Epoch 195/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.5706 - accuracy: 0.7800\n",
            "Epoch 196/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5687 - accuracy: 0.7933\n",
            "Epoch 197/200\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5670 - accuracy: 0.7933\n",
            "Epoch 198/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5656 - accuracy: 0.7933\n",
            "Epoch 199/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5637 - accuracy: 0.7933\n",
            "Epoch 200/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5622 - accuracy: 0.8000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7b2f9c12ded0>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('trained_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4nj_Ee-2wpa",
        "outputId": "597a3cfd-e206-4533-bf91-41af6c3eef8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# testing the model\n",
        "\n",
        "input_data = [5.5, 3.8, 1.7, 0.4]\n",
        "input_data_as_numpy_array = np.asarray(input_data)\n",
        "input_data_reshaped = input_data_as_numpy_array.reshape(1, -1)\n",
        "\n",
        "prediction_probabilities = model.predict(input_data_reshaped)\n",
        "\n",
        "predicted_class_index = np.argmax(prediction_probabilities)\n",
        "\n",
        "if predicted_class_index == 0:\n",
        "    print(\"Predicted class: setosa\")\n",
        "elif predicted_class_index == 1:\n",
        "    print(\"Predicted class: versicolor\")\n",
        "elif predicted_class_index == 2:\n",
        "    print(\"Predicted class: virginica\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nl_kt6gw7BDU",
        "outputId": "68fde3c2-9fd1-4162-8d8b-bcae66b1c98f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 125ms/step\n",
            "Predicted class: setosa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Exploring the parameters of the network**"
      ],
      "metadata": {
        "id": "jnz85SgAR4S_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# weights and biases between input and 1st hidden layer\n",
        "model.layers[1].get_weights()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVQezNCs27pI",
        "outputId": "7bd251b3-2a0e-46be-f1b8-d0553d88b96c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[-0.0392388 , -0.03945966,  0.0373222 ,  0.22560251,  0.06488997,\n",
              "          0.01979341],\n",
              "        [-0.03339946, -0.0142856 , -0.01222465,  0.25763494,  0.01669244,\n",
              "         -0.02003668],\n",
              "        [-0.03395408, -0.0438095 ,  0.4814633 , -0.23863757,  0.4384766 ,\n",
              "         -0.12280047],\n",
              "        [ 0.00981111,  0.02423311,  0.70935667, -0.5380099 ,  0.60929835,\n",
              "          0.02216373]], dtype=float32),\n",
              " array([ 0.        ,  0.        , -0.19145758,  0.36545086, -0.1568684 ,\n",
              "         0.        ], dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# weights and biases between 1st and 2nd hidden layer\n",
        "model.layers[2].get_weights()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCwk2QQo3zaw",
        "outputId": "e2928851-499b-4e05-e819-d02fd670e7bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[ 0.01558522, -0.08915482,  0.04402914,  0.00135766, -0.00896062,\n",
              "          0.01829775],\n",
              "        [-0.09426739,  0.00999466,  0.03378607, -0.02205719,  0.01856203,\n",
              "         -0.02601918],\n",
              "        [-0.09134047, -0.03646337, -0.01757221, -0.03630325, -0.04119295,\n",
              "          0.46405143],\n",
              "        [ 0.02677008, -0.04024647,  0.00597418, -0.09796111,  0.05201013,\n",
              "         -1.0875523 ],\n",
              "        [-0.09396843, -0.07093579, -0.01255743,  0.0162311 , -0.11023263,\n",
              "          0.40531498],\n",
              "        [-0.05888029,  0.06673779,  0.06025617,  0.06524397,  0.09662601,\n",
              "         -0.09679871]], dtype=float32),\n",
              " array([ 0.        ,  0.        ,  0.        , -0.00885382, -0.02539089,\n",
              "        -0.10390843], dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# weights and biases between 2nd and 3rd hidden layer\n",
        "model.layers[3].get_weights()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mz220J6G69xN",
        "outputId": "fa2d1006-0160-4b0b-da0a-fcacc48b3166"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[ 0.62302625,  0.52936697, -0.1567893 ],\n",
              "        [ 0.32470202,  0.640537  ,  0.32955635],\n",
              "        [-0.12751138,  0.7545353 ,  0.73499405],\n",
              "        [-0.08806525, -0.3569599 , -0.3887436 ],\n",
              "        [-0.62424815,  0.57807285, -0.73462856],\n",
              "        [-1.2868598 ,  0.19879529,  0.8453331 ]], dtype=float32),\n",
              " array([ 0.82192326,  0.22682633, -0.85470474], dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.layers[3].get_weights()[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XH0vof1CybY",
        "outputId": "db413c5f-eff0-475c-ec42-58aff7dbabd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.82192326,  0.22682633, -0.85470474], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Can make an array of all the weights as follows too"
      ],
      "metadata": {
        "id": "Ahe7Uy6uKDto"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params = model.get_weights()"
      ],
      "metadata": {
        "id": "qVe5M_4ImG2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuzJ1L22rhIN",
        "outputId": "1d6afa5b-174c-4e27-a5d2-e210f6911824"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[-0.0392388 , -0.03945966,  0.0373222 ,  0.22560251,  0.06488997,\n",
              "          0.01979341],\n",
              "        [-0.03339946, -0.0142856 , -0.01222465,  0.25763494,  0.01669244,\n",
              "         -0.02003668],\n",
              "        [-0.03395408, -0.0438095 ,  0.4814633 , -0.23863757,  0.4384766 ,\n",
              "         -0.12280047],\n",
              "        [ 0.00981111,  0.02423311,  0.70935667, -0.5380099 ,  0.60929835,\n",
              "          0.02216373]], dtype=float32),\n",
              " array([ 0.        ,  0.        , -0.19145758,  0.36545086, -0.1568684 ,\n",
              "         0.        ], dtype=float32),\n",
              " array([[ 0.01558522, -0.08915482,  0.04402914,  0.00135766, -0.00896062,\n",
              "          0.01829775],\n",
              "        [-0.09426739,  0.00999466,  0.03378607, -0.02205719,  0.01856203,\n",
              "         -0.02601918],\n",
              "        [-0.09134047, -0.03646337, -0.01757221, -0.03630325, -0.04119295,\n",
              "          0.46405143],\n",
              "        [ 0.02677008, -0.04024647,  0.00597418, -0.09796111,  0.05201013,\n",
              "         -1.0875523 ],\n",
              "        [-0.09396843, -0.07093579, -0.01255743,  0.0162311 , -0.11023263,\n",
              "          0.40531498],\n",
              "        [-0.05888029,  0.06673779,  0.06025617,  0.06524397,  0.09662601,\n",
              "         -0.09679871]], dtype=float32),\n",
              " array([ 0.        ,  0.        ,  0.        , -0.00885382, -0.02539089,\n",
              "        -0.10390843], dtype=float32),\n",
              " array([[ 0.62302625,  0.52936697, -0.1567893 ],\n",
              "        [ 0.32470202,  0.640537  ,  0.32955635],\n",
              "        [-0.12751138,  0.7545353 ,  0.73499405],\n",
              "        [-0.08806525, -0.3569599 , -0.3887436 ],\n",
              "        [-0.62424815,  0.57807285, -0.73462856],\n",
              "        [-1.2868598 ,  0.19879529,  0.8453331 ]], dtype=float32),\n",
              " array([ 0.82192326,  0.22682633, -0.85470474], dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating an `all_weights` & `all_biases` list for easier access in future.\n",
        "example `all_weights[0]` will have weights for all the connection b/w input and 1st hidden layer"
      ],
      "metadata": {
        "id": "HgCyVl_dRKs2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_weights = []\n",
        "all_biases = []\n",
        "for i in range(0,6):\n",
        "  if (i%2 == 0):\n",
        "    all_weights.append(params[i])\n",
        "  else:\n",
        "    all_biases.append(params[i])"
      ],
      "metadata": {
        "id": "zsE78AHBKw-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4-JzaYVRB24",
        "outputId": "7102583c-34aa-4321-9d12-0ec59522691b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[-0.0392388 , -0.03945966,  0.0373222 ,  0.22560251,  0.06488997,\n",
              "          0.01979341],\n",
              "        [-0.03339946, -0.0142856 , -0.01222465,  0.25763494,  0.01669244,\n",
              "         -0.02003668],\n",
              "        [-0.03395408, -0.0438095 ,  0.4814633 , -0.23863757,  0.4384766 ,\n",
              "         -0.12280047],\n",
              "        [ 0.00981111,  0.02423311,  0.70935667, -0.5380099 ,  0.60929835,\n",
              "          0.02216373]], dtype=float32),\n",
              " array([[ 0.01558522, -0.08915482,  0.04402914,  0.00135766, -0.00896062,\n",
              "          0.01829775],\n",
              "        [-0.09426739,  0.00999466,  0.03378607, -0.02205719,  0.01856203,\n",
              "         -0.02601918],\n",
              "        [-0.09134047, -0.03646337, -0.01757221, -0.03630325, -0.04119295,\n",
              "          0.46405143],\n",
              "        [ 0.02677008, -0.04024647,  0.00597418, -0.09796111,  0.05201013,\n",
              "         -1.0875523 ],\n",
              "        [-0.09396843, -0.07093579, -0.01255743,  0.0162311 , -0.11023263,\n",
              "          0.40531498],\n",
              "        [-0.05888029,  0.06673779,  0.06025617,  0.06524397,  0.09662601,\n",
              "         -0.09679871]], dtype=float32),\n",
              " array([[ 0.62302625,  0.52936697, -0.1567893 ],\n",
              "        [ 0.32470202,  0.640537  ,  0.32955635],\n",
              "        [-0.12751138,  0.7545353 ,  0.73499405],\n",
              "        [-0.08806525, -0.3569599 , -0.3887436 ],\n",
              "        [-0.62424815,  0.57807285, -0.73462856],\n",
              "        [-1.2868598 ,  0.19879529,  0.8453331 ]], dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_biases"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9mtj6NORdBD",
        "outputId": "b9772a09-e45c-4932-f6ab-e0db80de4294"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([ 0.        ,  0.        , -0.19145758,  0.36545086, -0.1568684 ,\n",
              "         0.        ], dtype=float32),\n",
              " array([ 0.        ,  0.        ,  0.        , -0.00885382, -0.02539089,\n",
              "        -0.10390843], dtype=float32),\n",
              " array([ 0.82192326,  0.22682633, -0.85470474], dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## **Representing Sympy matrices for the output layer**\n",
        "Representing the symbolic expression in a simplified manner."
      ],
      "metadata": {
        "id": "tO8CwliCz9MZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w = sp.Matrix(all_weights[2])"
      ],
      "metadata": {
        "id": "Xuvg9U-Bmio2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Weights matrix b/w 2nd hidden layer and output layer, here each column represents weights from previous layer's 6 neurons for each output neuron"
      ],
      "metadata": {
        "id": "AROw8nC9mfoX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "CCJSipyAIrWB",
        "outputId": "5791105f-591e-4296-8473-59ee4110f299"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Matrix([\n",
              "[  0.623026, 0.529367, -0.156789],\n",
              "[  0.324702, 0.640537,  0.329556],\n",
              "[ -0.127511, 0.754535,  0.734994],\n",
              "[-0.0880653, -0.35696, -0.388744],\n",
              "[ -0.624248, 0.578073, -0.734629],\n",
              "[  -1.28686, 0.198795,  0.845333]])"
            ],
            "text/latex": "$\\displaystyle \\left[\\begin{matrix}0.623026 & 0.529367 & -0.156789\\\\0.324702 & 0.640537 & 0.329556\\\\-0.127511 & 0.754535 & 0.734994\\\\-0.0880653 & -0.35696 & -0.388744\\\\-0.624248 & 0.578073 & -0.734629\\\\-1.28686 & 0.198795 & 0.845333\\end{matrix}\\right]$"
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Neuron values of 2nd hidden layer**, represented by $x_{2i}$ which can be further opened i.e can be written in the format of previous layer's neuron values which can be further written in terms of input values.\n",
        "\n",
        "For the sake of simplicity I would here be representing the symbolic expression in the terms of $x_{2i}$ only.\n",
        "\n",
        "In the next section you'll have the option to see the full expression with input features as the only variables"
      ],
      "metadata": {
        "id": "-5JIYUDyIzsN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_out = sp.Matrix([sp.symbols(f'x2_{i+1}') for i in range(6)])"
      ],
      "metadata": {
        "id": "yDrJLHcrDgPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "WGoHJiKPItKj",
        "outputId": "89e8d798-77cc-4370-f1b6-42ed4900ceb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Matrix([\n",
              "[x2_1],\n",
              "[x2_2],\n",
              "[x2_3],\n",
              "[x2_4],\n",
              "[x2_5],\n",
              "[x2_6]])"
            ],
            "text/latex": "$\\displaystyle \\left[\\begin{matrix}x_{2 1}\\\\x_{2 2}\\\\x_{2 3}\\\\x_{2 4}\\\\x_{2 5}\\\\x_{2 6}\\end{matrix}\\right]$"
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Biases matrix for each neuron in the output layer"
      ],
      "metadata": {
        "id": "4VtbGcre0Y9M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "b = sp.Matrix(all_biases[2])"
      ],
      "metadata": {
        "id": "8RaR9vj0zu8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 78
        },
        "id": "ScSWep79EBsD",
        "outputId": "a6a2b309-6f55-4e5f-833d-1ef0fc99b97b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Matrix([\n",
              "[ 0.821923],\n",
              "[ 0.226826],\n",
              "[-0.854705]])"
            ],
            "text/latex": "$\\displaystyle \\left[\\begin{matrix}0.821923\\\\0.226826\\\\-0.854705\\end{matrix}\\right]$"
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sp.Matrix(w.T * hidden_out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 78
        },
        "id": "7vHqFMODEGlv",
        "outputId": "cf0f9847-8b34-41b0-ba34-ce1743a5c2fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Matrix([\n",
              "[ 0.623026*x2_1 + 0.324702*x2_2 - 0.127511*x2_3 - 0.0880653*x2_4 - 0.624248*x2_5 - 1.28686*x2_6],\n",
              "[  0.529367*x2_1 + 0.640537*x2_2 + 0.754535*x2_3 - 0.35696*x2_4 + 0.578073*x2_5 + 0.198795*x2_6],\n",
              "[-0.156789*x2_1 + 0.329556*x2_2 + 0.734994*x2_3 - 0.388744*x2_4 - 0.734629*x2_5 + 0.845333*x2_6]])"
            ],
            "text/latex": "$\\displaystyle \\left[\\begin{matrix}0.623026 x_{2 1} + 0.324702 x_{2 2} - 0.127511 x_{2 3} - 0.0880653 x_{2 4} - 0.624248 x_{2 5} - 1.28686 x_{2 6}\\\\0.529367 x_{2 1} + 0.640537 x_{2 2} + 0.754535 x_{2 3} - 0.35696 x_{2 4} + 0.578073 x_{2 5} + 0.198795 x_{2 6}\\\\- 0.156789 x_{2 1} + 0.329556 x_{2 2} + 0.734994 x_{2 3} - 0.388744 x_{2 4} - 0.734629 x_{2 5} + 0.845333 x_{2 6}\\end{matrix}\\right]$"
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Final symbolic representation of output layer will be after applying softmax activation function to the `pre_final`"
      ],
      "metadata": {
        "id": "n4NOMFAaJLNn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pre_final = sp.Matrix(w.T * hidden_out + b)"
      ],
      "metadata": {
        "id": "mAF3TvOqEVPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pre_final"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 78
        },
        "id": "QqBPhWYADlVX",
        "outputId": "2e225b7a-0b53-4210-c03d-939107b00a50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Matrix([\n",
              "[ 0.623026*x2_1 + 0.324702*x2_2 - 0.127511*x2_3 - 0.0880653*x2_4 - 0.624248*x2_5 - 1.28686*x2_6 + 0.821923],\n",
              "[  0.529367*x2_1 + 0.640537*x2_2 + 0.754535*x2_3 - 0.35696*x2_4 + 0.578073*x2_5 + 0.198795*x2_6 + 0.226826],\n",
              "[-0.156789*x2_1 + 0.329556*x2_2 + 0.734994*x2_3 - 0.388744*x2_4 - 0.734629*x2_5 + 0.845333*x2_6 - 0.854705]])"
            ],
            "text/latex": "$\\displaystyle \\left[\\begin{matrix}0.623026 x_{2 1} + 0.324702 x_{2 2} - 0.127511 x_{2 3} - 0.0880653 x_{2 4} - 0.624248 x_{2 5} - 1.28686 x_{2 6} + 0.821923\\\\0.529367 x_{2 1} + 0.640537 x_{2 2} + 0.754535 x_{2 3} - 0.35696 x_{2 4} + 0.578073 x_{2 5} + 0.198795 x_{2 6} + 0.226826\\\\- 0.156789 x_{2 1} + 0.329556 x_{2 2} + 0.734994 x_{2 3} - 0.388744 x_{2 4} - 0.734629 x_{2 5} + 0.845333 x_{2 6} - 0.854705\\end{matrix}\\right]$"
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Writing the math equation with input features as variables**\n",
        "\n",
        "Plan:\n",
        "- Using `all_weights[0]` and `all_biases[0]` get values of neurons in hidden layer 1 after applying `relu` activation as defined in the model architecture\n",
        "- Then similarly using those neuron values as inputs compute values of neurons of hidden layer 2 and then finally get the output_layer after using `softmax` classifier to get final prediction."
      ],
      "metadata": {
        "id": "P4nNzEdySCdn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Important info about the function below**\n",
        "- You'll have the option to view the the symbolic representation and the prediction made by taking the symbolic expression from the output layer as input.\n",
        "- To view the expression input 1 when prompted and to view the prediction input 2 when prompted."
      ],
      "metadata": {
        "id": "OyXxMsGEm2wz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def symbolic_eq_gen(input_values=None):\n",
        "\n",
        "  '''\n",
        "  This function gives the symbolic representation or the prediction according to your choice\n",
        "  '''\n",
        "\n",
        "  x_symbols = sp.symbols(\"x0:4\")  # Creates x0, x1, x2, x3 as symbols\n",
        "  x = sp.Matrix(x_symbols)\n",
        "\n",
        "  # if input_values is None:\n",
        "  user_choice = int(input(\"Enter 1 to get the symbolic representation, or 2 to predict the flower class using that symbolic expression: \"))\n",
        "  if user_choice == 2:\n",
        "      input_values = input(\"Enter 4 comma-separated values for x0, x1, x2, x3, (default values : 5.5, 3.8, 1.7, 0.4): \")\n",
        "      # if empty input give x some default value\n",
        "      if input_values.strip() == \"\":\n",
        "        input_values = \"5.5, 3.8, 1.7, 0.4\"\n",
        "      print(f\"Input values are : {input_values}\")\n",
        "\n",
        "  # Parse input values as a list of floats\n",
        "  if input_values:\n",
        "      input_values = [float(val) for val in input_values.split(',')]\n",
        "      # If input values are provided, substitute them into the symbol matrix\n",
        "      if len(input_values) == 4:\n",
        "          x = x.subs({x_symbols[i]: input_values[i] for i in range(4)})\n",
        "\n",
        "  #Getting the params values from the lists created earlier and putting them in a sympy matrix\n",
        "  w0 = sp.Matrix(all_weights[0])\n",
        "  b0 = sp.Matrix(all_biases[0])\n",
        "  w1 = sp.Matrix(all_weights[1])\n",
        "  b1 = sp.Matrix(all_biases[1])\n",
        "  w2 = sp.Matrix(all_weights[2])\n",
        "  b2 = sp.Matrix(all_biases[2])\n",
        "\n",
        "  # Calculating a1, h1, a2, h2, a3 using sympy operations\n",
        "  a1 = w0.T * x + b0\n",
        "  h1 = sp.Matrix([sp.Max(element, 0) for element in a1]) # RelU activation\n",
        "  a2 = w1.T * h1 + b1\n",
        "  h2 = sp.Matrix([sp.Max(element, 0) for element in a2]) # RelU activation\n",
        "  a3 = w2.T * h2 + b2\n",
        "\n",
        "  # Softmax activation to get probability\n",
        "  softmax_denominator = sp.Add(*a3.applyfunc(sp.exp))\n",
        "  h3 = a3.applyfunc(lambda val: sp.exp(val) / softmax_denominator)\n",
        "\n",
        "  return user_choice, h3"
      ],
      "metadata": {
        "id": "QyUACiKDflTv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the equation in this cell:\n",
        "\n",
        "user_choice, result_h3 = symbolic_eq_gen()\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "if (user_choice == 2):\n",
        "  h_values = [result_h3[0],result_h3[1], result_h3[2]]\n",
        "  flower_class = ['Setosa', 'Versicolor', 'Virginica']\n",
        "  max_idx = np.argmax(h_values)\n",
        "  print(f\"The values of output layer after softmax activation are -> {result_h3}\")\n",
        "  print(f\"Implying the flower class is {flower_class[max_idx]}\")\n",
        "else:\n",
        "  print(\"The symbolic representation of the output layer in terms of input variables(i.e x0,x1,x2,x3) is:\")\n",
        "  print(result_h3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gG7N2GkPduhT",
        "outputId": "070a4cdc-52ee-4181-9909-75ec5d198989"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter 1 to get the symbolic representation, or 2 to predict the flower class using that symbolic expression: 1\n",
            "--------------------------------------------------------------------------------------------------\n",
            "The symbolic representation of the output layer in terms of input variables(i.e x0,x1,x2,x3) is:\n",
            "Matrix([[2.27487*exp(0.623026*Max(0, -0.0942674*Max(0, -0.0394597*x0 - 0.0142856*x1 - 0.0438095*x2 + 0.0242331*x3) + 0.0155852*Max(0, -0.0392388*x0 - 0.0333995*x1 - 0.0339541*x2 + 0.00981111*x3) - 0.0588803*Max(0, 0.0197934*x0 - 0.0200367*x1 - 0.1228*x2 + 0.0221637*x3) - 0.0913405*Max(0, 0.0373222*x0 - 0.0122247*x1 + 0.481463*x2 + 0.709357*x3 - 0.191458) - 0.0939684*Max(0, 0.06489*x0 + 0.0166924*x1 + 0.438477*x2 + 0.609298*x3 - 0.156868) + 0.0267701*Max(0, 0.225603*x0 + 0.257635*x1 - 0.238638*x2 - 0.53801*x3 + 0.365451)) + 0.324702*Max(0, 0.00999466*Max(0, -0.0394597*x0 - 0.0142856*x1 - 0.0438095*x2 + 0.0242331*x3) - 0.0891548*Max(0, -0.0392388*x0 - 0.0333995*x1 - 0.0339541*x2 + 0.00981111*x3) + 0.0667378*Max(0, 0.0197934*x0 - 0.0200367*x1 - 0.1228*x2 + 0.0221637*x3) - 0.0364634*Max(0, 0.0373222*x0 - 0.0122247*x1 + 0.481463*x2 + 0.709357*x3 - 0.191458) - 0.0709358*Max(0, 0.06489*x0 + 0.0166924*x1 + 0.438477*x2 + 0.609298*x3 - 0.156868) - 0.0402465*Max(0, 0.225603*x0 + 0.257635*x1 - 0.238638*x2 - 0.53801*x3 + 0.365451)) - 0.127511*Max(0, 0.0337861*Max(0, -0.0394597*x0 - 0.0142856*x1 - 0.0438095*x2 + 0.0242331*x3) + 0.0440291*Max(0, -0.0392388*x0 - 0.0333995*x1 - 0.0339541*x2 + 0.00981111*x3) + 0.0602562*Max(0, 0.0197934*x0 - 0.0200367*x1 - 0.1228*x2 + 0.0221637*x3) - 0.0175722*Max(0, 0.0373222*x0 - 0.0122247*x1 + 0.481463*x2 + 0.709357*x3 - 0.191458) - 0.0125574*Max(0, 0.06489*x0 + 0.0166924*x1 + 0.438477*x2 + 0.609298*x3 - 0.156868) + 0.00597418*Max(0, 0.225603*x0 + 0.257635*x1 - 0.238638*x2 - 0.53801*x3 + 0.365451)) - 1.28686*Max(0, -0.0260192*Max(0, -0.0394597*x0 - 0.0142856*x1 - 0.0438095*x2 + 0.0242331*x3) + 0.0182977*Max(0, -0.0392388*x0 - 0.0333995*x1 - 0.0339541*x2 + 0.00981111*x3) - 0.0967987*Max(0, 0.0197934*x0 - 0.0200367*x1 - 0.1228*x2 + 0.0221637*x3) + 0.464051*Max(0, 0.0373222*x0 - 0.0122247*x1 + 0.481463*x2 + 0.709357*x3 - 0.191458) + 0.405315*Max(0, 0.06489*x0 + 0.0166924*x1 + 0.438477*x2 + 0.609298*x3 - 0.156868) - 1.08755*Max(0, 0.225603*x0 + 0.257635*x1 - 0.238638*x2 - 0.53801*x3 + 0.365451) - 0.103908) - 0.0880653*Max(0, -0.0220572*Max(0, -0.0394597*x0 - 0.0142856*x1 - 0.0438095*x2 + 0.0242331*x3) + 0.00135766*Max(0, -0.0392388*x0 - 0.0333995*x1 - 0.0339541*x2 + 0.00981111*x3) + 0.065244*Max(0, 0.0197934*x0 - 0.0200367*x1 - 0.1228*x2 + 0.0221637*x3) - 0.0363033*Max(0, 0.0373222*x0 - 0.0122247*x1 + 0.481463*x2 + 0.709357*x3 - 0.191458) + 0.0162311*Max(0, 0.06489*x0 + 0.0166924*x1 + 0.438477*x2 + 0.609298*x3 - 0.156868) - 0.0979611*Max(0, 0.225603*x0 + 0.257635*x1 - 0.238638*x2 - 0.53801*x3 + 0.365451) - 0.00885382) - 0.624248*Max(0, 0.018562*Max(0, -0.0394597*x0 - 0.0142856*x1 - 0.0438095*x2 + 0.0242331*x3) - 0.00896062*Max(0, -0.0392388*x0 - 0.0333995*x1 - 0.0339541*x2 + 0.00981111*x3) + 0.096626*Max(0, 0.0197934*x0 - 0.0200367*x1 - 0.1228*x2 + 0.0221637*x3) - 0.0411929*Max(0, 0.0373222*x0 - 0.0122247*x1 + 0.481463*x2 + 0.709357*x3 - 0.191458) - 0.110233*Max(0, 0.06489*x0 + 0.0166924*x1 + 0.438477*x2 + 0.609298*x3 - 0.156868) + 0.0520101*Max(0, 0.225603*x0 + 0.257635*x1 - 0.238638*x2 - 0.53801*x3 + 0.365451) - 0.0253909))/(0.425409*exp(-0.156789*Max(0, -0.0942674*Max(0, -0.0394597*x0 - 0.0142856*x1 - 0.0438095*x2 + 0.0242331*x3) + 0.0155852*Max(0, -0.0392388*x0 - 0.0333995*x1 - 0.0339541*x2 + 0.00981111*x3) - 0.0588803*Max(0, 0.0197934*x0 - 0.0200367*x1 - 0.1228*x2 + 0.0221637*x3) - 0.0913405*Max(0, 0.0373222*x0 - 0.0122247*x1 + 0.481463*x2 + 0.709357*x3 - 0.191458) - 0.0939684*Max(0, 0.06489*x0 + 0.0166924*x1 + 0.438477*x2 + 0.609298*x3 - 0.156868) + 0.0267701*Max(0, 0.225603*x0 + 0.257635*x1 - 0.238638*x2 - 0.53801*x3 + 0.365451)) + 0.329556*Max(0, 0.00999466*Max(0, -0.0394597*x0 - 0.0142856*x1 - 0.0438095*x2 + 0.0242331*x3) - 0.0891548*Max(0, -0.0392388*x0 - 0.0333995*x1 - 0.0339541*x2 + 0.00981111*x3) + 0.0667378*Max(0, 0.0197934*x0 - 0.0200367*x1 - 0.1228*x2 + 0.0221637*x3) - 0.0364634*Max(0, 0.0373222*x0 - 0.0122247*x1 + 0.481463*x2 + 0.709357*x3 - 0.191458) - 0.0709358*Max(0, 0.06489*x0 + 0.0166924*x1 + 0.438477*x2 + 0.609298*x3 - 0.156868) - 0.0402465*Max(0, 0.225603*x0 + 0.257635*x1 - 0.238638*x2 - 0.53801*x3 + 0.365451)) + 0.734994*Max(0, 0.0337861*Max(0, -0.0394597*x0 - 0.0142856*x1 - 0.0438095*x2 + 0.0242331*x3) + 0.0440291*Max(0, -0.0392388*x0 - 0.0333995*x1 - 0.0339541*x2 + 0.00981111*x3) + 0.0602562*Max(0, 0.0197934*x0 - 0.0200367*x1 - 0.1228*x2 + 0.0221637*x3) - 0.0175722*Max(0, 0.0373222*x0 - 0.0122247*x1 + 0.481463*x2 + 0.709357*x3 - 0.191458) - 0.0125574*Max(0, 0.06489*x0 + 0.0166924*x1 + 0.438477*x2 + 0.609298*x3 - 0.156868) + 0.00597418*Max(0, 0.225603*x0 + 0.257635*x1 - 0.238638*x2 - 0.53801*x3 + 0.365451)) + 0.845333*Max(0, -0.0260192*Max(0, -0.0394597*x0 - 0.0142856*x1 - 0.0438095*x2 + 0.0242331*x3) + 0.0182977*Max(0, -0.0392388*x0 - 0.0333995*x1 - 0.0339541*x2 + 0.00981111*x3) - 0.0967987*Max(0, 0.0197934*x0 - 0.0200367*x1 - 0.1228*x2 + 0.0221637*x3) + 0.464051*Max(0, 0.0373222*x0 - 0.0122247*x1 + 0.481463*x2 + 0.709357*x3 - 0.191458) + 0.405315*Max(0, 0.06489*x0 + 0.0166924*x1 + 0.438477*x2 + 0.609298*x3 - 0.156868) - 1.08755*Max(0, 0.225603*x0 + 0.257635*x1 - 0.238638*x2 - 0.53801*x3 + 0.365451) - 0.103908) - 0.388744*Max(0, -0.0220572*Max(0, -0.0394597*x0 - 0.0142856*x1 - 0.0438095*x2 + 0.0242331*x3) + 0.00135766*Max(0, -0.0392388*x0 - 0.0333995*x1 - 0.0339541*x2 + 0.00981111*x3) + 0.065244*Max(0, 0.0197934*x0 - 0.0200367*x1 - 0.1228*x2 + 0.0221637*x3) - 0.0363033*Max(0, 0.0373222*x0 - 0.0122247*x1 + 0.481463*x2 + 0.709357*x3 - 0.191458) + 0.0162311*Max(0, 0.06489*x0 + 0.0166924*x1 + 0.438477*x2 + 0.609298*x3 - 0.156868) - 0.0979611*Max(0, 0.225603*x0 + 0.257635*x1 - 0.238638*x2 - 0.53801*x3 + 0.365451) - 0.00885382) - 0.734629*Max(0, 0.018562*Max(0, -0.0394597*x0 - 0.0142856*x1 - 0.0438095*x2 + 0.0242331*x3) - 0.00896062*Max(0, -0.0392388*x0 - 0.0333995*x1 - 0.0339541*x2 + 0.00981111*x3) + 0.096626*Max(0, 0.0197934*x0 - 0.0200367*x1 - 0.1228*x2 + 0.0221637*x3) - 0.0411929*Max(0, 0.0373222*x0 - 0.0122247*x1 + 0.481463*x2 + 0.709357*x3 - 0.191458) - 0.110233*Max(0, 0.06489*x0 + 0.0166924*x1 + 0.438477*x2 + 0.609298*x3 - 0.156868) + 0.0520101*Max(0, 0.225603*x0 + 0.257635*x1 - 0.238638*x2 - 0.53801*x3 + 0.365451) - 0.0253909)) + 1.25461*exp(0.529367*Max(0, -0.0942674*Max(0, -0.0394597*x0 - 0.0142856*x1 - 0.0438095*x2 + 0.0242331*x3) + 0.0155852*Max(0, -0.0392388*x0 - 0.0333995*x1 - 0.0339541*x2 + 0.00981111*x3) - 0.0588803*Max(0, 0.0197934*x0 - 0.0200367*x1 - 0.1228*x2 + 0.0221637*x3) - 0.0913405*Max(0, 0.0373222*x0 - 0.0122247*x1 + 0.481463*x2 + 0.709357*x3 - 0.191458) - 0.0939684*Max(0, 0.06489*x0 + 0.0166924*x1 + 0.438477*x2 + 0.609298*x3 - 0.156868) + 0.0267701*Max(0, 0.225603*x0 + 0.257635*x1 - 0.238638*x2 - 0.53801*x3 + 0.365451)) + 0.640537*Max(0, 0.00999466*Max(0, -0.0394597*x0 - 0.0142856*x1 - 0.0438095*x2 + 0.0242331*x3) - 0.0891548*Max(0, -0.0392388*x0 - 0.0333995*x1 - 0.0339541*x2 + 0.00981111*x3) + 0.0667378*Max(0, 0.0197934*x0 - 0.0200367*x1 - 0.1228*x2 + 0.0221637*x3) - 0.0364634*Max(0, 0.0373222*x0 - 0.0122247*x1 + 0.481463*x2 + 0.709357*x3 - 0.191458) - 0.0709358*Max(0, 0.06489*x0 + 0.0166924*x1 + 0.438477*x2 + 0.609298*x3 - 0.156868) - 0.0402465*Max(0, 0.225603*x0 + 0.257635*x1 - 0.238638*x2 - 0.53801*x3 + 0.365451)) + 0.754535*Max(0, 0.0337861*Max(0, -0.0394597*x0 - 0.0142856*x1 - 0.0438095*x2 + 0.0242331*x3) + 0.0440291*Max(0, -0.0392388*x0 - 0.0333995*x1 - 0.0339541*x2 + 0.00981111*x3) + 0.0602562*Max(0, 0.0197934*x0 - 0.0200367*x1 - 0.1228*x2 + 0.0221637*x3) - 0.0175722*Max(0, 0.0373222*x0 - 0.0122247*x1 + 0.481463*x2 + 0.709357*x3 - 0.191458) - 0.0125574*Max(0, 0.06489*x0 + 0.0166924*x1 + 0.438477*x2 + 0.609298*x3 - 0.156868) + 0.00597418*Max(0, 0.225603*x0 + 0.257635*x1 - 0.238638*x2 - 0.53801*x3 + 0.365451)) + 0.198795*Max(0, -0.0260192*Max(0, -0.0394597*x0 - 0.0142856*x1 - 0.0438095*x2 + 0.0242331*x3) + 0.0182977*Max(0, -0.0392388*x0 - 0.0333995*x1 - 0.0339541*x2 + 0.00981111*x3) - 0.0967987*Max(0, 0.0197934*x0 - 0.0200367*x1 - 0.1228*x2 + 0.0221637*x3) + 0.464051*Max(0, 0.0373222*x0 - 0.0122247*x1 + 0.481463*x2 + 0.709357*x3 - 0.191458) + 0.405315*Max(0, 0.06489*x0 + 0.0166924*x1 + 0.438477*x2 + 0.609298*x3 - 0.156868) - 1.08755*Max(0, 0.225603*x0 + 0.257635*x1 - 0.238638*x2 - 0.53801*x3 + 0.365451) - 0.103908) - 0.35696*Max(0, -0.0220572*Max(0, -0.0394597*x0 - 0.0142856*x1 - 0.0438095*x2 + 0.0242331*x3) + 0.00135766*Max(0, -0.0392388*x0 - 0.0333995*x1 - 0.0339541*x2 + 0.00981111*x3) + 0.065244*Max(0, 0.0197934*x0 - 0.0200367*x1 - 0.1228*x2 + 0.0221637*x3) - 0.0363033*Max(0, 0.0373222*x0 - 0.0122247*x1 + 0.481463*x2 + 0.709357*x3 - 0.191458) + 0.0162311*Max(0, 0.06489*x0 + 0.0166924*x1 + 0.438477*x2 + 0.609298*x3 - 0.156868) - 0.0979611*Max(0, 0.225603*x0 + 0.257635*x1 - 0.238638*x2 - 0.53801*x3 + 0.365451) - 0.00885382) + 0.578073*Max(0, 0.018562*Max(0, -0.0394597*x0 - 0.0142856*x1 - 0.0438095*x2 + 0.0242331*x3) - 0.00896062*Max(0, -0.0392388*x0 - 0.0333995*x1 - 0.0339541*x2 + 0.00981111*x3) + 0.096626*Max(0, 0.0197934*x0 - 0.0200367*x1 - 0.1228*x2 + 0.0221637*x3) - 0.0411929*Max(0, 0.0373222*x0 - 0.0122247*x1 + 0.481463*x2 + 0.709357*x3 - 0.191458) - 0.110233*Max(0, 0.06489*x0 + 0.0166924*x1 + 0.438477*x2 + 0.609298*x3 - 0.156868) + 0.0520101*Max(0, 0.225603*x0 + 0.257635*x1 - 0.238638*x2 - 0.53801*x3 + 0.365451) - 0.0253909)) + 2.27487*exp(0.623026*Max(0, -0.0942674*Max(0, -0.0394597*x0 - 0.0142856*x1 - 0.0438095*x2 + 0.0242331*x3) + 0.0155852*Max(0, -0.0392388*x0 - 0.0333995*x1 - 0.0339541*x2 + 0.00981111*x3) - 0.0588803*Max(0, 0.0197934*x0 - 0.0200367*x1 - 0.1228*x2 + 0.0221637*x3) - 0.0913405*Max(0, 0.0373222*x0 - 0.0122247*x1 + 0.481463*x2 + 0.709357*x3 - 0.191458) - 0.0939684*Max(0, 0.06489*x0 + 0.0166924*x1 + 0.438477*x2 + 0.609298*x3 - 0.156868) + 0.0267701*Max(0, 0.225603*x0 + 0.257635*x1 - 0.238638*x2 - 0.53801*x3 + 0.365451)) + 0.324702*Max(0, 0.00999466*Max(0, -0.0394597*x0 - 0.0142856*x1 - 0.0438095*x2 + 0.0242331*x3) - 0.0891548*Max(0, -0.0392388*x0 - 0.0333995*x1 - 0.0339541*x2 + 0.00981111*x3) + 0.0667378*Max(0, 0.0197934*x0 - 0.0200367*x1 - 0.1228*x2 + 0.0221637*x3) - 0.0364634*Max(0, 0.0373222*x0 - 0.0122247*x1 + 0.481463*x2 + 0.709357*x3 - 0.191458) - 0.0709358*Max(0, 0.06489*x0 + 0.0166924*x1 + 0.438477*x2 + 0.609298*x3 - 0.156868) - 0.0402465*Max(0, 0.225603*x0 + 0.257635*x1 - 0.238638*x2 - 0.53801*x3 + 0.365451)) - 0.127511*Max(0, 0.0337861*Max(0, -0.0394597*x0 - 0.0142856*x1 - 0.0438095*x2 + 0.0242331*x3) + 0.0440291*Max(0, -0.0392388*x0 - 0.0333995*x1 - 0.0339541*x2 + 0.00981111*x3) + 0.0602562*Max(0, 0.0197934*x0 - 0.0200367*x1 - 0.1228*x2 + 0.0221637*x3) - 0.0175722*Max(0, 0.0373222*x0 - 0.0122247*x1 + 0.481463*x2 + 0.709357*x3 - 0.191458) - 0.0125574*Max(0, 0.06489*x0 + 0.0166924*x1 + 0.438477*x2 + 0.609298*x3 - 0.156868) + 0.00597418*Max(0, 0.225603*x0 + 0.257635*x1 - 0.238638*x2 - 0.53801*x3 + 0.365451)) - 1.28686*Max(0, -0.0260192*Max(0, -0.0394597*x0 - 0.0142856*x1 - 0.0438095*x2 + 0.0242331*x3) + 0.0182977*Max(0, -0.0392388*x0 - 0.0333995*x1 - 0.0339541*x2 + 0.00981111*x3) - 0.0967987*Max(0, 0.0197934*x0 - 0.0200367*x1 - 0.1228*x2 + 0.0221637*x3) + 0.464051*Max(0, 0.0373222*x0 - 0.0122247*x1 + 0.481463*x2 + 0.709357*x3 - 0.191458) + 0.405315*Max(0, 0.06489*x0 + 0.0166924*x1 + 0.438477*x2 + 0.609298*x3 - 0.156868) - 1.08755*Max(0, 0.225603*x0 + 0.257635*x1 - 0.238638*x2 - 0.53801*x3 + 0.365451) - 0.103908) - 0.0880653*Max(0, -0.0220572*Max(0, -0.0394597*x0 - 0.0142856*x1 - 0.0438095*x2 + 0.0242331*x3) + 0.00135766*Max(0, -0.0392388*x0 - 0.0333995*x1 - 0.0339541*x2 + 0.00981111*x3) + 0.065244*Max(0, 0.0197934*x0 - 0.0200367*x1 - 0.1228*x2 + 0.0221637*x3) - 0.0363033*Max(0, 0.0373222*x0 - 0.0122247*x1 + 0.481463*x2 + 0.709357*x3 - 0.191458) + 0.0162311*Max(0, 0.06489*x0 + 0.0166924*x1 + 0.438477*x2 + 0.609298*x3 - 0.156868) - 0.0979611*Max(0, 0.225603*x0 + 0.257635*x1 - 0.238638*x2 - 0.53801*x3 + 0.365451) - 0.00885382) - 0.624248*Max(0, 0.018562*Max(0, -0.0394597*x0 - 0.0142856*x1 - 0.0438095*x2 + 0.0242331*x3) - 0.00896062*Max(0, -0.0392388*x0 - 0.0333995*x1 - 0.0339541*x2 + 0.00981111*x3) + 0.096626*Max(0, 0.0197934*x0 - 0.0200367*x1 - 0.1228*x2 + 0.0221637*x3) - 0.0411929*Max(0, 0.0373222*x0 - 0.0122247*x1 + 0.481463*x2 + 0.709357*x3 - 0.191458) - 0.110233*Max(0, 0.06489*x0 + 0.0166924*x1 + 0.438477*x2 + 0.609298*x3 - 0.156868) + 0.0520101*Max(0, 0.225603*x0 + 0.257635*x1 - 0.238638*x2 - 0.53801*x3 + 0.365451) - 0.0253909)))], [1.25461*exp(0.529367*Max(0, -0.0942674*Max(0, -0.0394597*x0 - 0.0142856*x1 - 0.0438095*x2 + 0.0242331*x3) + 0.0155852*Max(0, -0.0392388*x0 - 0.0333995*x1 - 0.0339541*x2 + 0.00981111*x3) - 0.0588803*Max(0, 0.0197934*x0 - 0.0200367*x1 - 0.1228*x2 + 0.0221637*x3) - 0.0913405*Max(0, 0.0373222*x0 - 0.0122247*x1 + 0.481463*x2 + 0.709357*x3 - 0.191458) - 0.0939684*Max(0, 0.06489*x0 + 0.0166924*x1 + 0.438477*x2 + 0.609298*x3 - 0.156868) + 0.0267701*Max(0, 0.225603*x0 + 0.257635*x1 - 0.238638*x2 - 0.53801*x3 + 0.365451)) + 0.640537*Max(0, 0.00999466*Max(0, -0.0394597*x0 - 0.0142856*x1 - 0.0438095*x2 + 0.0242331*x3) - 0.0891548*Max(0, -0.0392388*x0 - 0.0333995*x1 - 0.0339541*x2 + 0.00981111*x3) + 0.0667378*Max(0, 0.0197934*x0 - 0.0200367*x1 - 0.1228*x2 + 0.0221637*x3) - 0.0364634*Max(0, 0.0373222*x0 - 0.0122247*x1 + 0.481463*x2 + 0.709357*x3 - 0.191458) - 0.0709358*Max(0, 0.06489*x0 + 0.0166924*x1 + 0.438477*x2 + 0.609298*x3 - 0.156868) - 0.0402465*Max(0, 0.225603*x0 + 0.257635*x1 - 0.238638*x2 - 0.53801*x3 + 0.365451)) + 0.754535*Max(0, 0.0337861*Max(0, -0.0394597*x0 - 0.0142856*x1 - 0.0438095*x2 + 0.0242331*x3) + 0.0440291*Max(0, -0.0392388*x0 - 0.0333995*x1 - 0.0339541*x2 + 0.00981111*x3) + 0.0602562*Max(0, 0.0197934*x0 - 0.0200367*x1 - 0.1228*x2 + 0.0221637*x3) - 0.0175722*Max(0, 0.0373222*x0 - 0.0122247*x1 + 0.481463*x2 + 0.709357*x3 - 0.191458) - 0.0125574*Max(0, 0.06489*x0 + 0.0166924*x1 + 0.438477*x2 + 0.609298*x3 - 0.156868) + 0.00597418*Max(0, 0.225603*x0 + 0.257635*x1 - 0.238638*x2 - 0.53801*x3 + 0.365451)) + 0.198795*Max(0, -0.0260192*Max(0, -0.0394597*x0 - 0.0142856*x1 - 0.0438095*x2 + 0.0242331*x3) + 0.0182977*Max(0, -0.0392388*x0 - 0.0333995*x1 - 0.0339541*x2 + 0.00981111*x3) - 0.0967987*Max(0, 0.0197934*x0 - 0.0200367*x1 - 0.1228*x2 + 0.0221637*x3) + 0.464051*Max(0, 0.0373222*x0 - 0.0122247*x1 + 0.481463*x2 + 0.709357*x3 - 0.191458) + 0.405315*Max(0, 0.06489*x0 + 0.0166924*x1 + 0.438477*x2 + 0.609298*x3 - 0.156868) - 1.08755*Max(0, 0.225603*x0 + 0.257635*x1 - 0.238638*x2 - 0.53801*x3 + 0.365451) - 0.103908) - 0.35696*Max(0, -0.0220572*Max(0, -0.0394597*x0 - 0.0142856*x1 - 0.0438095*x2 + 0.0242331*x3) + 0.00135766*Max(0, -0.0392388*x0 - 0.0333995*x1 - 0.0339541*x2 + 0.00981111*x3) + 0.065244*Max(0, 0.0197934*x0 - 0.0200367*x1 - 0.1228*x2 + 0.0221637*x3) - 0.0363033*Max(0, 0.0373222*x0 - 0.0122247*x1 + 0.481463*x2 + 0.709357*x3 - 0.191458) + 0.0162311*Max(0, 0.06489*x0 + 0.0166924*x1 + 0.438477*x2 + 0.609298*x3 - 0.156868) - 0.0979611*Max(0, 0.225603*x0 + 0.257635*x1 - 0.238638*x2 - 0.53801*x3 + 0.365451) - 0.00885382) + 0.578073*Max(0, 0.018562*Max(0, -0.0394597*x0 - 0.0142856*x1 - 0.0438095*x2 + 0.0242331*x3) - 0.00896062*Max(0, -0.0392388*x0 - 0.0333995*x1 - 0.0339541*x2 + 0.00981111*x3) + 0.096626*Max(0, 0.0197934*x0 - 0.0200367*x1 - 0.1228*x2 + 0.0221637*x3) - 0.0411929*Max(0, 0.0373222*x0 - 0.0122247*x1 + 0.481463*x2 + 0.709357*x3 - 0.191458) - 0.110233*Max(0, 0.06489*x0 + 0.0166924*x1 + 0.438477*x2 + 0.609298*x3 - 0.156868) + 0.0520101*Max(0, 0.225603*x0 + 0.257635*x1 - 0.238638*x2 - 0.53801*x3 + 0.365451) - 0.0253909))/(0.425409*exp(-0.156789*Max(0, -0.0942674*Max(0, -0.0394597*x0 - 0.0142856*x1 - 0.0438095*x2 + 0.0242331*x3) + 0.0155852*Max(0, -0.0392388*x0 - 0.0333995*x1 - 0.0339541*x2 + 0.00981111*x3) - 0.0588803*Max(0, 0.0197934*x0 - 0.0200367*x1 - 0.1228*x2 + 0.0221637*x3) - 0.0913405*Max(0, 0.0373222*x0 - 0.0122247*x1 + 0.481463*x2 + 0.709357*x3 - 0.191458) - 0.0939684*Max(0, 0.06489*x0 + 0.0166924*x1 + 0.438477*x2 + 0.609298*x3 - 0.156868) + 0.0267701*Max(0, 0.225603*x0 + 0.257635*x1 - 0.238638*x2 - 0.53801*x3 + 0.365451)) + 0.329556*Max(0, 0.00999466*Max(0, -0.0394597*x0 - 0.0142856*x1 - 0.0438095*x2 + 0.0242331*x3) - 0.0891548*Max(0, -0.0392388*x0 - 0.0333995*x1 - 0.0339541*x2 + 0.00981111*x3) + 0.0667378*Max(0, 0.0197934*x0 - 0.0200367*x1 - 0.1228*x2 + 0.0221637*x3) - 0.0364634*Max(0, 0.0373222*x0 - 0.0122247*x1 + 0.481463*x2 + 0.709357*x3 - 0.191458) - 0.0709358*Max(0, 0.06489*x0 + 0.0166924*x1 + 0.438477*x2 + 0.609298*x3 - 0.156868) - 0.0402465*Max(0, 0.225603*x0 + 0.257635*x1 - 0.238638*x2 - 0.53801*x3 + 0.365451)) + 0.734994*Max(0, 0.0337861*Max(0, -0.0394597*x0 - 0.0142856*x1 - 0.0438095*x2 + 0.0242331*x3) + 0.0440291*Max(0, -0.0392388*x0 - 0.0333995*x1 - 0.0339541*x2 + 0.00981111*x3) + 0.0602562*Max(0, 0.0197934*x0 - 0.0200367*x1 - 0.1228*x2 + 0.0221637*x3) - 0.0175722*Max(0, 0.0373222*x0 - 0.0122247*x1 + 0.481463*x2 + 0.709357*x3 - 0.191458) - 0.0125574*Max(0, 0.06489*x0 + 0.0166924*x1 + 0.438477*x2 + 0.609298*x3 - 0.156868) + 0.00597418*Max(0, 0.225603*x0 + 0.257635*x1 - 0.238638*x2 - 0.53801*x3 + 0.365451)) + 0.845333*Max(0, -0.0260192*Max(0, -0.0394597*x0 - 0.0142856*x1 - 0.0438095*x2 + 0.0242331*x3) + 0.0182977*Max(0, -0.0392388*x0 - 0.0333995*x1 - 0.0339541*x2 + 0.00981111*x3) - 0.0967987*Max(0, 0.0197934*x0 - 0.0200367*x1 - 0.1228*x2 + 0.0221637*x3) + 0.464051*Max(0, 0.0373222*x0 - 0.0122247*x1 + 0.481463*x2 + 0.709357*x3 - 0.191458) + 0.405315*Max(0, 0.06489*x0 + 0.0166924*x1 + 0.438477*x2 + 0.609298*x3 - 0.156868) - 1.08755*Max(0, 0.225603*x0 + 0.257635*x1 - 0.238638*x2 - 0.53801*x3 + 0.365451) - 0.103908) - 0.388744*Max(0, -0.0220572*Max(0, -0.0394597*x0 - 0.0142856*x1 - 0.0438095*x2 + 0.0242331*x3) + 0.00135766*Max(0, -0.0392388*x0 - 0.0333995*x1 - 0.0339541*x2 + 0.00981111*x3) + 0.065244*Max(0, 0.0197934*x0 - 0.0200367*x1 - 0.1228*x2 + 0.0221637*x3) - 0.0363033*Max(0, 0.0373222*x0 - 0.0122247*x1 + 0.481463*x2 + 0.709357*x3 - 0.191458) + 0.0162311*Max(0, 0.06489*x0 + 0.0166924*x1 + 0.438477*x2 + 0.609298*x3 - 0.156868) - 0.0979611*Max(0, 0.225603*x0 + 0.257635*x1 - 0.238638*x2 - 0.53801*x3 + 0.365451) - 0.00885382) - 0.734629*Max(0, 0.018562*Max(0, -0.0394597*x0 - 0.0142856*x1 - 0.0438095*x2 + 0.0242331*x3) - 0.00896062*Max(0, -0.0392388*x0 - 0.0333995*x1 - 0.0339541*x2 + 0.00981111*x3) + 0.096626*Max(0, 0.0197934*x0 - 0.0200367*x1 - 0.1228*x2 + 0.0221637*x3) - 0.0411929*Max(0, 0.0373222*x0 - 0.0122247*x1 + 0.481463*x2 + 0.709357*x3 - 0.191458) - 0.110233*Max(0, 0.06489*x0 + 0.0166924*x1 + 0.438477*x2 + 0.609298*x3 - 0.156868) + 0.0520101*Max(0, 0.225603*x0 + 0.257635*x1 - 0.238638*x2 - 0.53801*x3 + 0.365451) - 0.0253909)) + 1.25461*exp(0.529367*Max(0, -0.0942674*Max(0, -0.0394597*x0 - 0.0142856*x1 - 0.0438095*x2 + 0.0242331*x3) + 0.0155852*Max(0, -0.0392388*x0 - 0.0333995*x1 - 0.0339541*x2 + 0.00981111*x3) - 0.0588803*Max(0, 0.0197934*x0 - 0.0200367*x1 - 0.1228*x2 + 0.0221637*x3) - 0.0913405*Max(0, 0.0373222*x0 - 0.0122247*x1 + 0.481463*x2 + 0.709357*x3 - 0.191458) - 0.0939684*Max(0, 0.06489*x0 + 0.0166924*x1 + 0.438477*x2 + 0.609298*x3 - 0.156868) + 0.0267701*Max(0, 0.225603*x0 + 0.257635*x1 - 0.238638*x2 - 0.53801*x3 + 0.365451)) + 0.640537*Max(0, 0.00999466*Max(0, -0.0394597*x0 - 0.0142856*x1 - 0.0438095*x2 + 0.0242331*x3) - 0.0891548*Max(0, -0.0392388*x0 - 0.0333995*x1 - 0.0339541*x2 + 0.00981111*x3) + 0.0667378*Max(0, 0.0197934*x0 - 0.0200367*x1 - 0.1228*x2 + 0.0221637*x3) - 0.0364634*Max(0, 0.0373222*x0 - 0.0122247*x1 + 0.481463*x2 + 0.709357*x3 - 0.191458) - 0.0709358*Max(0, 0.06489*x0 + 0.0166924*x1 + 0.438477*x2 + 0.609298*x3 - 0.156868) - 0.0402465*Max(0, 0.225603*x0 + 0.257635*x1 - 0.238638*x2 - 0.53801*x3 + 0.365451)) + 0.754535*Max(0, 0.0337861*Max(0, -0.0394597*x0 - 0.0142856*x1 - 0.0438095*x2 + 0.0242331*x3) + 0.0440291*Max(0, -0.0392388*x0 - 0.0333995*x1 - 0.0339541*x2 + 0.00981111*x3) + 0.0602562*Max(0, 0.0197934*x0 - 0.0200367*x1 - 0.1228*x2 + 0.0221637*x3) - 0.0175722*Max(0, 0.0373222*x0 - 0.0122247*x1 + 0.481463*x2 + 0.709357*x3 - 0.191458) - 0.0125574*Max(0, 0.06489*x0 + 0.0166924*x1 + 0.438477*x2 + 0.609298*x3 - 0.156868) + 0.00597418*Max(0, 0.225603*x0 + 0.257635*x1 - 0.238638*x2 - 0.53801*x3 + 0.365451)) + 0.198795*Max(0, -0.0260192*Max(0, -0.0394597*x0 - 0.0142856*x1 - 0.0438095*x2 + 0.0242331*x3) + 0.0182977*Max(0, -0.0392388*x0 - 0.0333995*x1 - 0.0339541*x2 + 0.00981111*x3) - 0.0967987*Max(0, 0.0197934*x0 - 0.0200367*x1 - 0.1228*x2 + 0.0221637*x3) + 0.464051*Max(0, 0.0373222*x0 - 0.0122247*x1 + 0.481463*x2 + 0.709357*x3 - 0.191458) + 0.405315*Max(0, 0.06489*x0 + 0.0166924*x1 + 0.438477*x2 + 0.609298*x3 - 0.156868) - 1.08755*Max(0, 0.225603*x0 + 0.257635*x1 - 0.238638*x2 - 0.53801*x3 + 0.365451) - 0.103908) - 0.35696*Max(0, -0.0220572*Max(0, -0.0394597*x0 - 0.0142856*x1 - 0.0438095*x2 + 0.0242331*x3) + 0.00135766*Max(0, -0.0392388*x0 - 0.0333995*x1 - 0.0339541*x2 + 0.00981111*x3) + 0.065244*Max(0, 0.0197934*x0 - 0.0200367*x1 - 0.1228*x2 + 0.0221637*x3) - 0.0363033*Max(0, 0.0373222*x0 - 0.0122247*x1 + 0.481463*x2 + 0.709357*x3 - 0.191458) + 0.0162311*Max(0, 0.06489*x0 + 0.0166924*x1 + 0.438477*x2 + 0.609298*x3 - 0.156868) - 0.0979611*Max(0, 0.225603*x0 + 0.257635*x1 - 0.238638*x2 - 0.53801*x3 + 0.365451) - 0.00885382) + 0.578073*Max(0, 0.018562*Max(0, -0.0394597*x0 - 0.0142856*x1 - 0.0438095*x2 + 0.0242331*x3) - 0.00896062*Max(0, -0.0392388*x0 - 0.0333995*x1 - 0.0339541*x2 + 0.00981111*x3) + 0.096626*Max(0, 0.0197934*x0 - 0.0200367*x1 - 0.1228*x2 + 0.0221637*x3) - 0.0411929*Max(0, 0.0373222*x0 - 0.0122247*x1 + 0.481463*x2 + 0.709357*x3 - 0.191458) - 0.110233*Max(0, 0.06489*x0 + 0.0166924*x1 + 0.438477*x2 + 0.609298*x3 - 0.156868) + 0.0520101*Max(0, 0.225603*x0 + 0.257635*x1 - 0.238638*x2 - 0.53801*x3 + 0.365451) - 0.0253909)) + 2.27487*exp(0.623026*Max(0, -0.0942674*Max(0, -0.0394597*x0 - 0.0142856*x1 - 0.0438095*x2 + 0.0242331*x3) + 0.0155852*Max(0, -0.0392388*x0 - 0.0333995*x1 - 0.0339541*x2 + 0.00981111*x3) - 0.0588803*Max(0, 0.0197934*x0 - 0.0200367*x1 - 0.1228*x2 + 0.0221637*x3) - 0.0913405*Max(0, 0.0373222*x0 - 0.0122247*x1 + 0.481463*x2 + 0.709357*x3 - 0.191458) - 0.0939684*Max(0, 0.06489*x0 + 0.0166924*x1 + 0.438477*x2 + 0.609298*x3 - 0.156868) + 0.0267701*Max(0, 0.225603*x0 + 0.257635*x1 - 0.238638*x2 - 0.53801*x3 + 0.365451)) + 0.324702*Max(0, 0.00999466*Max(0, -0.0394597*x0 - 0.0142856*x1 - 0.0438095*x2 + 0.0242331*x3) - 0.0891548*Max(0, -0.0392388*x0 - 0.0333995*x1 - 0.0339541*x2 + 0.00981111*x3) + 0.0667378*Max(0, 0.0197934*x0 - 0.0200367*x1 - 0.1228*x2 + 0.0221637*x3) - 0.0364634*Max(0, 0.0373222*x0 - 0.0122247*x1 + 0.481463*x2 + 0.709357*x3 - 0.191458) - 0.0709358*Max(0, 0.06489*x0 + 0.0166924*x1 + 0.438477*x2 + 0.609298*x3 - 0.156868) - 0.0402465*Max(0, 0.225603*x0 + 0.257635*x1 - 0.238638*x2 - 0.53801*x3 + 0.365451)) - 0.127511*Max(0, 0.0337861*Max(0, -0.0394597*x0 - 0.0142856*x1 - 0.0438095*x2 + 0.0242331*x3) + 0.0440291*Max(0, -0.0392388*x0 - 0.0333995*x1 - 0.0339541*x2 + 0.00981111*x3) + 0.0602562*Max(0, 0.0197934*x0 - 0.0200367*x1 - 0.1228*x2 + 0.0221637*x3) - 0.0175722*Max(0, 0.0373222*x0 - 0.0122247*x1 + 0.481463*x2 + 0.709357*x3 - 0.191458) - 0.0125574*Max(0, 0.06489*x0 + 0.0166924*x1 + 0.438477*x2 + 0.609298*x3 - 0.156868) + 0.00597418*Max(0, 0.225603*x0 + 0.257635*x1 - 0.238638*x2 - 0.53801*x3 + 0.365451)) - 1.28686*Max(0, -0.0260192*Max(0, -0.0394597*x0 - 0.0142856*x1 - 0.0438095*x2 + 0.0242331*x3) + 0.0182977*Max(0, -0.0392388*x0 - 0.0333995*x1 - 0.0339541*x2 + 0.00981111*x3) - 0.0967987*Max(0, 0.0197934*x0 - 0.0200367*x1 - 0.1228*x2 + 0.0221637*x3) + 0.464051*Max(0, 0.0373222*x0 - 0.0122247*x1 + 0.481463*x2 + 0.709357*x3 - 0.191458) + 0.405315*Max(0, 0.06489*x0 + 0.0166924*x1 + 0.438477*x2 + 0.609298*x3 - 0.156868) - 1.08755*Max(0, 0.225603*x0 + 0.257635*x1 - 0.238638*x2 - 0.53801*x3 + 0.365451) - 0.103908) - 0.0880653*Max(0, -0.0220572*Max(0, -0.0394597*x0 - 0.0142856*x1 - 0.0438095*x2 + 0.0242331*x3) + 0.00135766*Max(0, -0.0392388*x0 - 0.0333995*x1 - 0.0339541*x2 + 0.00981111*x3) + 0.065244*Max(0, 0.0197934*x0 - 0.0200367*x1 - 0.1228*x2 + 0.0221637*x3) - 0.0363033*Max(0, 0.0373222*x0 - 0.0122247*x1 + 0.481463*x2 + 0.709357*x3 - 0.191458) + 0.0162311*Max(0, 0.06489*x0 + 0.0166924*x1 + 0.438477*x2 + 0.609298*x3 - 0.156868) - 0.0979611*Max(0, 0.225603*x0 + 0.257635*x1 - 0.238638*x2 - 0.53801*x3 + 0.365451) - 0.00885382) - 0.624248*Max(0, 0.018562*Max(0, -0.0394597*x0 - 0.0142856*x1 - 0.0438095*x2 + 0.0242331*x3) - 0.00896062*Max(0, -0.0392388*x0 - 0.0333995*x1 - 0.0339541*x2 + 0.00981111*x3) + 0.096626*Max(0, 0.0197934*x0 - 0.0200367*x1 - 0.1228*x2 + 0.0221637*x3) - 0.0411929*Max(0, 0.0373222*x0 - 0.0122247*x1 + 0.481463*x2 + 0.709357*x3 - 0.191458) - 0.110233*Max(0, 0.06489*x0 + 0.0166924*x1 + 0.438477*x2 + 0.609298*x3 - 0.156868) + 0.0520101*Max(0, 0.225603*x0 + 0.257635*x1 - 0.238638*x2 - 0.53801*x3 + 0.365451) - 0.0253909)))], [0.425409*exp(-0.156789*Max(0, -0.0942674*Max(0, -0.0394597*x0 - 0.0142856*x1 - 0.0438095*x2 + 0.0242331*x3) + 0.0155852*Max(0, -0.0392388*x0 - 0.0333995*x1 - 0.0339541*x2 + 0.00981111*x3) - 0.0588803*Max(0, 0.0197934*x0 - 0.0200367*x1 - 0.1228*x2 + 0.0221637*x3) - 0.0913405*Max(0, 0.0373222*x0 - 0.0122247*x1 + 0.481463*x2 + 0.709357*x3 - 0.191458) - 0.0939684*Max(0, 0.06489*x0 + 0.0166924*x1 + 0.438477*x2 + 0.609298*x3 - 0.156868) + 0.0267701*Max(0, 0.225603*x0 + 0.257635*x1 - 0.238638*x2 - 0.53801*x3 + 0.365451)) + 0.329556*Max(0, 0.00999466*Max(0, -0.0394597*x0 - 0.0142856*x1 - 0.0438095*x2 + 0.0242331*x3) - 0.0891548*Max(0, -0.0392388*x0 - 0.0333995*x1 - 0.0339541*x2 + 0.00981111*x3) + 0.0667378*Max(0, 0.0197934*x0 - 0.0200367*x1 - 0.1228*x2 + 0.0221637*x3) - 0.0364634*Max(0, 0.0373222*x0 - 0.0122247*x1 + 0.481463*x2 + 0.709357*x3 - 0.191458) - 0.0709358*Max(0, 0.06489*x0 + 0.0166924*x1 + 0.438477*x2 + 0.609298*x3 - 0.156868) - 0.0402465*Max(0, 0.225603*x0 + 0.257635*x1 - 0.238638*x2 - 0.53801*x3 + 0.365451)) + 0.734994*Max(0, 0.0337861*Max(0, -0.0394597*x0 - 0.0142856*x1 - 0.0438095*x2 + 0.0242331*x3) + 0.0440291*Max(0, -0.0392388*x0 - 0.0333995*x1 - 0.0339541*x2 + 0.00981111*x3) + 0.0602562*Max(0, 0.0197934*x0 - 0.0200367*x1 - 0.1228*x2 + 0.0221637*x3) - 0.0175722*Max(0, 0.0373222*x0 - 0.0122247*x1 + 0.481463*x2 + 0.709357*x3 - 0.191458) - 0.0125574*Max(0, 0.06489*x0 + 0.0166924*x1 + 0.438477*x2 + 0.609298*x3 - 0.156868) + 0.00597418*Max(0, 0.225603*x0 + 0.257635*x1 - 0.238638*x2 - 0.53801*x3 + 0.365451)) + 0.845333*Max(0, -0.0260192*Max(0, -0.0394597*x0 - 0.0142856*x1 - 0.0438095*x2 + 0.0242331*x3) + 0.0182977*Max(0, -0.0392388*x0 - 0.0333995*x1 - 0.0339541*x2 + 0.00981111*x3) - 0.0967987*Max(0, 0.0197934*x0 - 0.0200367*x1 - 0.1228*x2 + 0.0221637*x3) + 0.464051*Max(0, 0.0373222*x0 - 0.0122247*x1 + 0.481463*x2 + 0.709357*x3 - 0.191458) + 0.405315*Max(0, 0.06489*x0 + 0.0166924*x1 + 0.438477*x2 + 0.609298*x3 - 0.156868) - 1.08755*Max(0, 0.225603*x0 + 0.257635*x1 - 0.238638*x2 - 0.53801*x3 + 0.365451) - 0.103908) - 0.388744*Max(0, -0.0220572*Max(0, -0.0394597*x0 - 0.0142856*x1 - 0.0438095*x2 + 0.0242331*x3) + 0.00135766*Max(0, -0.0392388*x0 - 0.0333995*x1 - 0.0339541*x2 + 0.00981111*x3) + 0.065244*Max(0, 0.0197934*x0 - 0.0200367*x1 - 0.1228*x2 + 0.0221637*x3) - 0.0363033*Max(0, 0.0373222*x0 - 0.0122247*x1 + 0.481463*x2 + 0.709357*x3 - 0.191458) + 0.0162311*Max(0, 0.06489*x0 + 0.0166924*x1 + 0.438477*x2 + 0.609298*x3 - 0.156868) - 0.0979611*Max(0, 0.225603*x0 + 0.257635*x1 - 0.238638*x2 - 0.53801*x3 + 0.365451) - 0.00885382) - 0.734629*Max(0, 0.018562*Max(0, -0.0394597*x0 - 0.0142856*x1 - 0.0438095*x2 + 0.0242331*x3) - 0.00896062*Max(0, -0.0392388*x0 - 0.0333995*x1 - 0.0339541*x2 + 0.00981111*x3) + 0.096626*Max(0, 0.0197934*x0 - 0.0200367*x1 - 0.1228*x2 + 0.0221637*x3) - 0.0411929*Max(0, 0.0373222*x0 - 0.0122247*x1 + 0.481463*x2 + 0.709357*x3 - 0.191458) - 0.110233*Max(0, 0.06489*x0 + 0.0166924*x1 + 0.438477*x2 + 0.609298*x3 - 0.156868) + 0.0520101*Max(0, 0.225603*x0 + 0.257635*x1 - 0.238638*x2 - 0.53801*x3 + 0.365451) - 0.0253909))/(0.425409*exp(-0.156789*Max(0, -0.0942674*Max(0, -0.0394597*x0 - 0.0142856*x1 - 0.0438095*x2 + 0.0242331*x3) + 0.0155852*Max(0, -0.0392388*x0 - 0.0333995*x1 - 0.0339541*x2 + 0.00981111*x3) - 0.0588803*Max(0, 0.0197934*x0 - 0.0200367*x1 - 0.1228*x2 + 0.0221637*x3) - 0.0913405*Max(0, 0.0373222*x0 - 0.0122247*x1 + 0.481463*x2 + 0.709357*x3 - 0.191458) - 0.0939684*Max(0, 0.06489*x0 + 0.0166924*x1 + 0.438477*x2 + 0.609298*x3 - 0.156868) + 0.0267701*Max(0, 0.225603*x0 + 0.257635*x1 - 0.238638*x2 - 0.53801*x3 + 0.365451)) + 0.329556*Max(0, 0.00999466*Max(0, -0.0394597*x0 - 0.0142856*x1 - 0.0438095*x2 + 0.0242331*x3) - 0.0891548*Max(0, -0.0392388*x0 - 0.0333995*x1 - 0.0339541*x2 + 0.00981111*x3) + 0.0667378*Max(0, 0.0197934*x0 - 0.0200367*x1 - 0.1228*x2 + 0.0221637*x3) - 0.0364634*Max(0, 0.0373222*x0 - 0.0122247*x1 + 0.481463*x2 + 0.709357*x3 - 0.191458) - 0.0709358*Max(0, 0.06489*x0 + 0.0166924*x1 + 0.438477*x2 + 0.609298*x3 - 0.156868) - 0.0402465*Max(0, 0.225603*x0 + 0.257635*x1 - 0.238638*x2 - 0.53801*x3 + 0.365451)) + 0.734994*Max(0, 0.0337861*Max(0, -0.0394597*x0 - 0.0142856*x1 - 0.0438095*x2 + 0.0242331*x3) + 0.0440291*Max(0, -0.0392388*x0 - 0.0333995*x1 - 0.0339541*x2 + 0.00981111*x3) + 0.0602562*Max(0, 0.0197934*x0 - 0.0200367*x1 - 0.1228*x2 + 0.0221637*x3) - 0.0175722*Max(0, 0.0373222*x0 - 0.0122247*x1 + 0.481463*x2 + 0.709357*x3 - 0.191458) - 0.0125574*Max(0, 0.06489*x0 + 0.0166924*x1 + 0.438477*x2 + 0.609298*x3 - 0.156868) + 0.00597418*Max(0, 0.225603*x0 + 0.257635*x1 - 0.238638*x2 - 0.53801*x3 + 0.365451)) + 0.845333*Max(0, -0.0260192*Max(0, -0.0394597*x0 - 0.0142856*x1 - 0.0438095*x2 + 0.0242331*x3) + 0.0182977*Max(0, -0.0392388*x0 - 0.0333995*x1 - 0.0339541*x2 + 0.00981111*x3) - 0.0967987*Max(0, 0.0197934*x0 - 0.0200367*x1 - 0.1228*x2 + 0.0221637*x3) + 0.464051*Max(0, 0.0373222*x0 - 0.0122247*x1 + 0.481463*x2 + 0.709357*x3 - 0.191458) + 0.405315*Max(0, 0.06489*x0 + 0.0166924*x1 + 0.438477*x2 + 0.609298*x3 - 0.156868) - 1.08755*Max(0, 0.225603*x0 + 0.257635*x1 - 0.238638*x2 - 0.53801*x3 + 0.365451) - 0.103908) - 0.388744*Max(0, -0.0220572*Max(0, -0.0394597*x0 - 0.0142856*x1 - 0.0438095*x2 + 0.0242331*x3) + 0.00135766*Max(0, -0.0392388*x0 - 0.0333995*x1 - 0.0339541*x2 + 0.00981111*x3) + 0.065244*Max(0, 0.0197934*x0 - 0.0200367*x1 - 0.1228*x2 + 0.0221637*x3) - 0.0363033*Max(0, 0.0373222*x0 - 0.0122247*x1 + 0.481463*x2 + 0.709357*x3 - 0.191458) + 0.0162311*Max(0, 0.06489*x0 + 0.0166924*x1 + 0.438477*x2 + 0.609298*x3 - 0.156868) - 0.0979611*Max(0, 0.225603*x0 + 0.257635*x1 - 0.238638*x2 - 0.53801*x3 + 0.365451) - 0.00885382) - 0.734629*Max(0, 0.018562*Max(0, -0.0394597*x0 - 0.0142856*x1 - 0.0438095*x2 + 0.0242331*x3) - 0.00896062*Max(0, -0.0392388*x0 - 0.0333995*x1 - 0.0339541*x2 + 0.00981111*x3) + 0.096626*Max(0, 0.0197934*x0 - 0.0200367*x1 - 0.1228*x2 + 0.0221637*x3) - 0.0411929*Max(0, 0.0373222*x0 - 0.0122247*x1 + 0.481463*x2 + 0.709357*x3 - 0.191458) - 0.110233*Max(0, 0.06489*x0 + 0.0166924*x1 + 0.438477*x2 + 0.609298*x3 - 0.156868) + 0.0520101*Max(0, 0.225603*x0 + 0.257635*x1 - 0.238638*x2 - 0.53801*x3 + 0.365451) - 0.0253909)) + 1.25461*exp(0.529367*Max(0, -0.0942674*Max(0, -0.0394597*x0 - 0.0142856*x1 - 0.0438095*x2 + 0.0242331*x3) + 0.0155852*Max(0, -0.0392388*x0 - 0.0333995*x1 - 0.0339541*x2 + 0.00981111*x3) - 0.0588803*Max(0, 0.0197934*x0 - 0.0200367*x1 - 0.1228*x2 + 0.0221637*x3) - 0.0913405*Max(0, 0.0373222*x0 - 0.0122247*x1 + 0.481463*x2 + 0.709357*x3 - 0.191458) - 0.0939684*Max(0, 0.06489*x0 + 0.0166924*x1 + 0.438477*x2 + 0.609298*x3 - 0.156868) + 0.0267701*Max(0, 0.225603*x0 + 0.257635*x1 - 0.238638*x2 - 0.53801*x3 + 0.365451)) + 0.640537*Max(0, 0.00999466*Max(0, -0.0394597*x0 - 0.0142856*x1 - 0.0438095*x2 + 0.0242331*x3) - 0.0891548*Max(0, -0.0392388*x0 - 0.0333995*x1 - 0.0339541*x2 + 0.00981111*x3) + 0.0667378*Max(0, 0.0197934*x0 - 0.0200367*x1 - 0.1228*x2 + 0.0221637*x3) - 0.0364634*Max(0, 0.0373222*x0 - 0.0122247*x1 + 0.481463*x2 + 0.709357*x3 - 0.191458) - 0.0709358*Max(0, 0.06489*x0 + 0.0166924*x1 + 0.438477*x2 + 0.609298*x3 - 0.156868) - 0.0402465*Max(0, 0.225603*x0 + 0.257635*x1 - 0.238638*x2 - 0.53801*x3 + 0.365451)) + 0.754535*Max(0, 0.0337861*Max(0, -0.0394597*x0 - 0.0142856*x1 - 0.0438095*x2 + 0.0242331*x3) + 0.0440291*Max(0, -0.0392388*x0 - 0.0333995*x1 - 0.0339541*x2 + 0.00981111*x3) + 0.0602562*Max(0, 0.0197934*x0 - 0.0200367*x1 - 0.1228*x2 + 0.0221637*x3) - 0.0175722*Max(0, 0.0373222*x0 - 0.0122247*x1 + 0.481463*x2 + 0.709357*x3 - 0.191458) - 0.0125574*Max(0, 0.06489*x0 + 0.0166924*x1 + 0.438477*x2 + 0.609298*x3 - 0.156868) + 0.00597418*Max(0, 0.225603*x0 + 0.257635*x1 - 0.238638*x2 - 0.53801*x3 + 0.365451)) + 0.198795*Max(0, -0.0260192*Max(0, -0.0394597*x0 - 0.0142856*x1 - 0.0438095*x2 + 0.0242331*x3) + 0.0182977*Max(0, -0.0392388*x0 - 0.0333995*x1 - 0.0339541*x2 + 0.00981111*x3) - 0.0967987*Max(0, 0.0197934*x0 - 0.0200367*x1 - 0.1228*x2 + 0.0221637*x3) + 0.464051*Max(0, 0.0373222*x0 - 0.0122247*x1 + 0.481463*x2 + 0.709357*x3 - 0.191458) + 0.405315*Max(0, 0.06489*x0 + 0.0166924*x1 + 0.438477*x2 + 0.609298*x3 - 0.156868) - 1.08755*Max(0, 0.225603*x0 + 0.257635*x1 - 0.238638*x2 - 0.53801*x3 + 0.365451) - 0.103908) - 0.35696*Max(0, -0.0220572*Max(0, -0.0394597*x0 - 0.0142856*x1 - 0.0438095*x2 + 0.0242331*x3) + 0.00135766*Max(0, -0.0392388*x0 - 0.0333995*x1 - 0.0339541*x2 + 0.00981111*x3) + 0.065244*Max(0, 0.0197934*x0 - 0.0200367*x1 - 0.1228*x2 + 0.0221637*x3) - 0.0363033*Max(0, 0.0373222*x0 - 0.0122247*x1 + 0.481463*x2 + 0.709357*x3 - 0.191458) + 0.0162311*Max(0, 0.06489*x0 + 0.0166924*x1 + 0.438477*x2 + 0.609298*x3 - 0.156868) - 0.0979611*Max(0, 0.225603*x0 + 0.257635*x1 - 0.238638*x2 - 0.53801*x3 + 0.365451) - 0.00885382) + 0.578073*Max(0, 0.018562*Max(0, -0.0394597*x0 - 0.0142856*x1 - 0.0438095*x2 + 0.0242331*x3) - 0.00896062*Max(0, -0.0392388*x0 - 0.0333995*x1 - 0.0339541*x2 + 0.00981111*x3) + 0.096626*Max(0, 0.0197934*x0 - 0.0200367*x1 - 0.1228*x2 + 0.0221637*x3) - 0.0411929*Max(0, 0.0373222*x0 - 0.0122247*x1 + 0.481463*x2 + 0.709357*x3 - 0.191458) - 0.110233*Max(0, 0.06489*x0 + 0.0166924*x1 + 0.438477*x2 + 0.609298*x3 - 0.156868) + 0.0520101*Max(0, 0.225603*x0 + 0.257635*x1 - 0.238638*x2 - 0.53801*x3 + 0.365451) - 0.0253909)) + 2.27487*exp(0.623026*Max(0, -0.0942674*Max(0, -0.0394597*x0 - 0.0142856*x1 - 0.0438095*x2 + 0.0242331*x3) + 0.0155852*Max(0, -0.0392388*x0 - 0.0333995*x1 - 0.0339541*x2 + 0.00981111*x3) - 0.0588803*Max(0, 0.0197934*x0 - 0.0200367*x1 - 0.1228*x2 + 0.0221637*x3) - 0.0913405*Max(0, 0.0373222*x0 - 0.0122247*x1 + 0.481463*x2 + 0.709357*x3 - 0.191458) - 0.0939684*Max(0, 0.06489*x0 + 0.0166924*x1 + 0.438477*x2 + 0.609298*x3 - 0.156868) + 0.0267701*Max(0, 0.225603*x0 + 0.257635*x1 - 0.238638*x2 - 0.53801*x3 + 0.365451)) + 0.324702*Max(0, 0.00999466*Max(0, -0.0394597*x0 - 0.0142856*x1 - 0.0438095*x2 + 0.0242331*x3) - 0.0891548*Max(0, -0.0392388*x0 - 0.0333995*x1 - 0.0339541*x2 + 0.00981111*x3) + 0.0667378*Max(0, 0.0197934*x0 - 0.0200367*x1 - 0.1228*x2 + 0.0221637*x3) - 0.0364634*Max(0, 0.0373222*x0 - 0.0122247*x1 + 0.481463*x2 + 0.709357*x3 - 0.191458) - 0.0709358*Max(0, 0.06489*x0 + 0.0166924*x1 + 0.438477*x2 + 0.609298*x3 - 0.156868) - 0.0402465*Max(0, 0.225603*x0 + 0.257635*x1 - 0.238638*x2 - 0.53801*x3 + 0.365451)) - 0.127511*Max(0, 0.0337861*Max(0, -0.0394597*x0 - 0.0142856*x1 - 0.0438095*x2 + 0.0242331*x3) + 0.0440291*Max(0, -0.0392388*x0 - 0.0333995*x1 - 0.0339541*x2 + 0.00981111*x3) + 0.0602562*Max(0, 0.0197934*x0 - 0.0200367*x1 - 0.1228*x2 + 0.0221637*x3) - 0.0175722*Max(0, 0.0373222*x0 - 0.0122247*x1 + 0.481463*x2 + 0.709357*x3 - 0.191458) - 0.0125574*Max(0, 0.06489*x0 + 0.0166924*x1 + 0.438477*x2 + 0.609298*x3 - 0.156868) + 0.00597418*Max(0, 0.225603*x0 + 0.257635*x1 - 0.238638*x2 - 0.53801*x3 + 0.365451)) - 1.28686*Max(0, -0.0260192*Max(0, -0.0394597*x0 - 0.0142856*x1 - 0.0438095*x2 + 0.0242331*x3) + 0.0182977*Max(0, -0.0392388*x0 - 0.0333995*x1 - 0.0339541*x2 + 0.00981111*x3) - 0.0967987*Max(0, 0.0197934*x0 - 0.0200367*x1 - 0.1228*x2 + 0.0221637*x3) + 0.464051*Max(0, 0.0373222*x0 - 0.0122247*x1 + 0.481463*x2 + 0.709357*x3 - 0.191458) + 0.405315*Max(0, 0.06489*x0 + 0.0166924*x1 + 0.438477*x2 + 0.609298*x3 - 0.156868) - 1.08755*Max(0, 0.225603*x0 + 0.257635*x1 - 0.238638*x2 - 0.53801*x3 + 0.365451) - 0.103908) - 0.0880653*Max(0, -0.0220572*Max(0, -0.0394597*x0 - 0.0142856*x1 - 0.0438095*x2 + 0.0242331*x3) + 0.00135766*Max(0, -0.0392388*x0 - 0.0333995*x1 - 0.0339541*x2 + 0.00981111*x3) + 0.065244*Max(0, 0.0197934*x0 - 0.0200367*x1 - 0.1228*x2 + 0.0221637*x3) - 0.0363033*Max(0, 0.0373222*x0 - 0.0122247*x1 + 0.481463*x2 + 0.709357*x3 - 0.191458) + 0.0162311*Max(0, 0.06489*x0 + 0.0166924*x1 + 0.438477*x2 + 0.609298*x3 - 0.156868) - 0.0979611*Max(0, 0.225603*x0 + 0.257635*x1 - 0.238638*x2 - 0.53801*x3 + 0.365451) - 0.00885382) - 0.624248*Max(0, 0.018562*Max(0, -0.0394597*x0 - 0.0142856*x1 - 0.0438095*x2 + 0.0242331*x3) - 0.00896062*Max(0, -0.0392388*x0 - 0.0333995*x1 - 0.0339541*x2 + 0.00981111*x3) + 0.096626*Max(0, 0.0197934*x0 - 0.0200367*x1 - 0.1228*x2 + 0.0221637*x3) - 0.0411929*Max(0, 0.0373222*x0 - 0.0122247*x1 + 0.481463*x2 + 0.709357*x3 - 0.191458) - 0.110233*Max(0, 0.06489*x0 + 0.0166924*x1 + 0.438477*x2 + 0.609298*x3 - 0.156868) + 0.0520101*Max(0, 0.225603*x0 + 0.257635*x1 - 0.238638*x2 - 0.53801*x3 + 0.365451) - 0.0253909)))]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the the prediction in this cell:\n",
        "\n",
        "user_choice, result_h3 = symbolic_eq_gen()\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "if (user_choice == 2):\n",
        "  h_values = [result_h3[0],result_h3[1], result_h3[2]]\n",
        "  flower_class = ['Setosa', 'Versicolor', 'Virginica']\n",
        "  max_idx = np.argmax(h_values)\n",
        "  print(f\"The values of output layer after softmax activation are -> {result_h3}\")\n",
        "  print(f\"Implying the flower class is {flower_class[max_idx]}\")\n",
        "else:\n",
        "  print(\"The symbolic representation of the output layer in terms of input variables(i.e x0,x1,x2,x3) is:\")\n",
        "  print(result_h3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78p7RZkHo4BR",
        "outputId": "aa0c9361-47c7-4e79-c768-48fc4e8a8437"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter 1 to get the symbolic representation, or 2 to predict the flower class using that symbolic expression: 2\n",
            "Enter 4 comma-separated values for x0, x1, x2, x3, (default values : 5.5, 3.8, 1.7, 0.4): \n",
            "Input values are : 5.5, 3.8, 1.7, 0.4\n",
            "--------------------------------------------------------------------------------------------------\n",
            "The values of output layer after softmax activation are -> Matrix([[0.575204], [0.317230], [0.107565]])\n",
            "Implying the flower class is Setosa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Numpy implementation**\n",
        "i did this to verify the above values\n",
        "\n",
        "conclusion : the above sympy ops are correct yay :)"
      ],
      "metadata": {
        "id": "VRrvWxUvjV4D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# input features\n",
        "# 5.5, 3.8, 1.7, 0.4\n",
        "\n",
        "input_values = input(\"Enter 4 comma-separated values for x0, x1, x2, x3, (default values : 5.5, 3.8, 1.7, 0.4): \")\n",
        "# if empty input give x some default value\n",
        "if input_values.strip() == \"\":\n",
        "  input_values = \"5.5, 3.8, 1.7, 0.4\"\n",
        "print(f\"Input values are : {input_values}\")\n",
        "\n",
        "input_values = [float(val) for val in input_values.split(',')]\n",
        "\n",
        "x = np.array(input_values)\n",
        "\n",
        "#calling the weights and biases from the trained neural network\n",
        "# weights array\n",
        "w0 = all_weights[0]\n",
        "w1 = all_weights[1]\n",
        "w2 = all_weights[2]\n",
        "\n",
        "# biases array\n",
        "b0 = all_biases[0]\n",
        "b1 = all_biases[1]\n",
        "b2 = all_biases[2]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vP6cyF57S87o",
        "outputId": "cf186faa-bd14-4ae7-adff-3fbb23b63ec4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter 4 comma-separated values for x0, x1, x2, x3, (default values : 5.5, 3.8, 1.7, 0.4): \n",
            "Input values are : 5.5, 3.8, 1.7, 0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# doing the math :)\n",
        "\n",
        "a1 = np.dot(x, w0) + b0\n",
        "h1 = np.maximum(0, a1)  # RelU activation layer\n",
        "a2 = np.dot(h1, w1) + b1\n",
        "h2 = np.maximum(0, a2) # RelU\n",
        "a3 = np.dot(h2, w2) + b2\n",
        "# h3 = np.exp(a3 - np.max(a3)) / np.sum(np.exp(a3 - np.max(a3))) # Softmax activation layer, subtracting the max element to increase numerical stability\n",
        "h3 = np.exp(a3) / np.sum(np.exp(a3))\n",
        "print(\"Output probabilities:\", h3)\n",
        "print(\"Final answer: \", max(h3))\n",
        "\n",
        "if max(h3) == h3[0]:\n",
        "    print(\"Predicted class: setosa\")\n",
        "elif max(h3) == h3[1]:\n",
        "    print(\"Predicted class: versicolor\")\n",
        "elif max(h3) == h3[2]:\n",
        "    print(\"Predicted class: virginica\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BGKo2PeXpST",
        "outputId": "bd711c1b-f47b-4e71-8445-8f886c7fac50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output probabilities: [0.57520435 0.31723043 0.10756522]\n",
            "Final answer:  0.5752043455180971\n",
            "Predicted class: setosa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## References:\n",
        "[Sympy](https://docs.sympy.org/latest/index.html) and some stackoverflow posts"
      ],
      "metadata": {
        "id": "Cw0vxzq4t2Z0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Shortcomings:\n",
        "\n",
        "Here I list some shortcomings in this code which I can fix which I didn't yet due to time constraint of the task\n",
        "\n",
        "- The code is hard-coded at many places like making arrays, calculating max values etc. which can be generalised for all cases.\n",
        "- The function `symbolic_eq_gen()` can either give the symbolic representation or the prediction at one time which can be improved."
      ],
      "metadata": {
        "id": "6QRmX_RhscUs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experience:\n",
        "Overall I had a nice experience doing this task and I got to know my current level.\n",
        "\n",
        "I got to know something new i.e we can represent the decision making of a neural net mathematically as i never pondered over the things happening inside the network"
      ],
      "metadata": {
        "id": "bOLhvSqztLVv"
      }
    }
  ]
}